{"meta":{"title":"曲径","subtitle":null,"description":null,"author":"王开","url":"https://wangkai1994.github.io","root":"/"},"pages":[],"posts":[{"title":"房多多容器化和容器云实践","slug":"fdd-dockerswarm","date":"2019-04-21T06:34:17.000Z","updated":"2019-04-24T11:36:32.462Z","comments":true,"path":"2019/04/21/fdd-dockerswarm/","link":"","permalink":"https://wangkai1994.github.io/2019/04/21/fdd-dockerswarm/","excerpt":"房多多容器化和容器云实践背景和意义房多多是国内首家移动互联网房产交易平台。作为迅速崛起的行业新生力量，房多多通过移动互联网工具，为开发商、经纪公司、买房卖房者搭建了一个高效的、可信赖的O2O房产交易平台。 房地产行业的复杂性和业务创新环境注定了房多多的产品特点是不断持续创新和持续高速迭代的，在不断探索业务的可能性的过程中，提高持续快速交付价值的能力和创新能力是必不可少的。 软件行业没有所谓的“银弹”，房多多在业务解耦微服务化以后，服务指数型的增长带来了许多运维方面的困扰。 在我们内部比较突出的矛盾有： 虚拟机的资源依靠维护文档人肉调度，机器调度效率低。 维护测试、预发布、生产等环境的成本高。 某个业务的稳定太依赖某台物理机的稳定性，且难以快速扩容。 业务需求变化快导致雪花服务器增多，难以维护； CI/CD 脚本复杂，新的需求难以快速交付。 在2018年房多多 IOPS（Infranstructure &amp; Ops） 团队开始了服务容器化和容器云的建设，调研后选择了 Swarm 作为了容器集群。 可能很多人看到这儿就会关掉，”都9012年了还有人用 Swarm ?” 虽然在Swarm在和Kubernetes的竞争中已处于下风，但是 Swarm 的灵活性、性能和易用性促进了我们的容器化推进，且在我们落地过程中没有出现过系统级的 bug和线上故障，目前已经在生产环境支撑数百个服务的运行，每日300次左右的变更。 容器和调度编排系统的引入给难以运维的微服务架构带来了质的改变，但是服务容器化和容器云在推进过程中也有不少的坑，希望给大家带来启发。","text":"房多多容器化和容器云实践背景和意义房多多是国内首家移动互联网房产交易平台。作为迅速崛起的行业新生力量，房多多通过移动互联网工具，为开发商、经纪公司、买房卖房者搭建了一个高效的、可信赖的O2O房产交易平台。 房地产行业的复杂性和业务创新环境注定了房多多的产品特点是不断持续创新和持续高速迭代的，在不断探索业务的可能性的过程中，提高持续快速交付价值的能力和创新能力是必不可少的。 软件行业没有所谓的“银弹”，房多多在业务解耦微服务化以后，服务指数型的增长带来了许多运维方面的困扰。 在我们内部比较突出的矛盾有： 虚拟机的资源依靠维护文档人肉调度，机器调度效率低。 维护测试、预发布、生产等环境的成本高。 某个业务的稳定太依赖某台物理机的稳定性，且难以快速扩容。 业务需求变化快导致雪花服务器增多，难以维护； CI/CD 脚本复杂，新的需求难以快速交付。 在2018年房多多 IOPS（Infranstructure &amp; Ops） 团队开始了服务容器化和容器云的建设，调研后选择了 Swarm 作为了容器集群。 可能很多人看到这儿就会关掉，”都9012年了还有人用 Swarm ?” 虽然在Swarm在和Kubernetes的竞争中已处于下风，但是 Swarm 的灵活性、性能和易用性促进了我们的容器化推进，且在我们落地过程中没有出现过系统级的 bug和线上故障，目前已经在生产环境支撑数百个服务的运行，每日300次左右的变更。 容器和调度编排系统的引入给难以运维的微服务架构带来了质的改变，但是服务容器化和容器云在推进过程中也有不少的坑，希望给大家带来启发。 选型在容器集群的选择上，Kubernetes事实上已成为容器届编排的标准，但是为什么我们选择了小众的 Docker Swarm呢？ 房多多的生产环境硬件基础设施基本都在 IDC 机房，物理机器数量大概有几百台，实际可以供业务迭代用的机器大概在一半左右，且没有很多空闲机器可供使用、新建容器云的机器需要腾挪现有业务。 根据上述的自身的情况，我们做容器平台调研时，主要从以下三点考虑 性能：用户可以在多短的时间内启动并大规模运行容器？系统在大负载情况下响应速度如何？ 易用性：起步时的学习曲线是什么？维持运转是否复杂？系统中有多少不定项？ 灵活性：是否可以和我当前的环境和工作流相整合？应用从开发到测试再到生产，是否可以无缝衔接？会不会被限制在某个平台上？ 1.从性能看：房多多是自建机房，每一台物理机的利用率是比较高的。在我们测试调研过程中发现，Swarm通常可以在一秒内启动一台容器,调度效率和容器启动速度其实比 Kubernetes快很多。如下图（50%负载下，1000节点 启动每一个容器的平均时间）： 2.从灵活性来看：Swarm 的 api 比较简单，可以很快的和现有的 DevOps 流程打通。且因为 Swarm 相当于Kubernetes 的子集，如果后面机器规模继续扩展，业务有大量编排需求，我们可以花不多的时间就可以迁移到Kubernetes上。其实只要我们的服务容器化了，后续更换什么容器集群其实问题都不大。 3.从易用性来看：API使用简单，资源抽象简单，可以快速启动上手。我们使用 Swarm 比较多的功能其实是调度功能，编排功能暂时没有大规模使用。Swarm 的结构比较简单，在最新的版本中内置分布式 k-v 数据库代替了 etcd，内置DNS用来服务发现。在规模中等情况下，几乎没有基础设施运维负担。 容器云架构Swarm 的实现和Kubernetes相似，最近的版本也在慢慢模仿 Kubernetes 的思想。 想了解如何搭建集群的操作可以查阅 Swarm 官网的文档。 因为 Manager 节点只负责调度集群的 Task ，配置要求不高，所以我们用虚拟化 Xenserver 虚拟了3台低配置机器（在不同的物理机上）作为 Manager 节点，根据 raft 算法，3台可以容许1台机器出问题，5台可以允许2台机器出问题，大家可以按需求部署。 Worker 节点的作用是运行业务容器，我们选择了直接用物理机来部署已达到最好的性能和资源利用。同时，在 Manager 和 Worker 节点上，会以容器方式部署机器监控和日志收集，上面还需要运行网络和存储插件。 都加入到集群之后，Swarm 会提供网络管理、负载均衡、基于DNS容器发现、集群状态管理、扩容缩容等功能，我们在 DevOps 流程层面，可以组合成发布、回滚应用、查看服务的状态、日志、终端，更改发布配置（例如环境变量、默认副本数等）等功能。这个层面我们引入了 Portainer 这个开源项目，提供了更好用集群管理的 UI 界面和类似Kubernetes Apiserver 设计的 docker 集群 API 接口服务。 Docker Swarm 的资源抽象比较简单，在没有容器编排的情况下，我们主要使用 Services，这个和Kubernetes上的 Services 有些不一样，可以理解为Services和Deployment 的合体，用来管理和定义 容器的调度和扩容等，也可以直接做端口映射，在容器集群里任意ip 都可以访问。 下图可以比较简单的描述我们是怎么把服务让外部和内部调用的： 外部调用我们通过 nginx 做反向代理到集群的节点，然后通过内置的 routing mesh 的 load balancer 通过 LVS 转发请求到service 的其中一个副本，一个值得注意的点是，就算这台 node 上没有运行这个 service 的容器load balancer也会找到其他机器上存在的副本，这个主要是通过 内置的 DNS 加 LVS转发实现。 内部调用我们是走我们的 Envoy Mesh 网关，通过自研的 xds-service 来自动发现加路由，本质是走容器之间互通的 overlay 网络 或者Macvlan 网络。 网络网络我们主要解决两个问题： 容器间互相通信 容器直接互相调用打通，并且可以作为基础的容器网卡，以支持容器集群的 routing mesh功能。 容器和外部网络互相通信 类似使用了dubbo 服务容器化，在虚拟机和容器并存的迁移过程中，必须要让容器和外部网络互通，不然会导致在容器集群外部的虚拟机调用不通容器。虽然也可以通过其他方法实现，但是打通容器和外部网络互相通信是较可行也是稳定的一种方法。 ​ 下图是我们主要的容器网络架构 容器间互通的解决方案是我们在容器集群中创建 overlay 网络，并将网络附加到容器容器上，容器中就有了名为 overlay的网卡(图中的 eth0)，每个容器的 eth0 都会经过宿主机的 docker0 网卡和 eth0与别的宿主机的网络进行交互。 容器与外部网络互通的解决方案是 Macvlan。其工作原理是通过为物理网卡创建Macvlan子接口，允许一块物理网卡拥有多个独立的MAC地址和IP地址。虚拟出来的子接口将直接暴露在底层物理网络中。从外界看来，就像是把网线分成多股，分别接到了不同的主机上一样，这样也可以拥有近似物理机直连的性能。 公有云一般会限制 Macvlan，不一定可以实施。因为我们是自建机房，所以没有这方面的限制，只要让网络工程师在交换机上配置好网段，我们就可以在此网段下分配容器的 ip 了。 具体使用方法是，在容器worker 节点创建一个 config-only 的 network，写划分的网段和网关，例子： 12docker network create --config-only --subnet=10.0.127.0/20 --gateway=10.0.112.1 --ip-range=10.0.112.0/25 -o parent=bond0 pub_net_config# bond0 为指定的依附的物理机网卡 然后在 manager 节点创建 network,例子： 1docker network create -d macvlan --scope swarm --config-from pub_net_config pub_net 然后只需要把网络附加到 service 上即可： 1docker service update m-web --network-add pub_net 容器化容器化首先是要把业务代码 build 成镜像，我们内部的技术栈主要以 Node 和 Java为主。 我们容器化迁移是先从 Node 服务开始，因为 Node 服务普遍比较新且项目都按照规范创建，没有很多历史债务且基本都是无状态的，这样我们就可以写出一个比较通用的 Dockerfile 让开发在迭代需求是时候顺便加上，基本只需要改一下暴露的端口号和监控检查 URL 就可以完成容器化。 Java 的构建工具主要以 Maven 和 Gradle 为主，我们使用了 Google 开源的 jib 工具来把构建 docker 镜像并上传的工作集成到 Maven 和 Gradle 中，实际操作只需要改一下 pom文件或者build.gradle，加入 jib plugins就可以了。 实际推广过程中，如果是还在迭代的项目，因为操作简单且容易理解，业务开发还是比较容易推动的。如果是历史项目且还运行在线上，可以让业务运维帮忙逐个操作，然后重新发布，测试，上线。 优化和Tips镜像大小优化镜像大小是容器化很重要的一个问题。镜像越小，容器发布和调度就越快，宿主机磁盘用量也不会过大。 除了大家常用的镜像优化手段比如减少层级等，我们优化基础镜像baseimage 使用了alpine3.9版本，并对使用到的基础库做了选择，比如使用最新的musl 1.1.21等，最终基础镜像控制42M，最终降低80%镜像大小到300M 以内。 信号量优化当容器的启动脚本是一个 shell 脚本时，因为 shell 不响应退出信号的特性，会导致容器无法正常退出，只能等超时后自动杀死进程，这样在我们的实践中会导致物理机上有很多僵尸进程。所以我们的解决方案是消除进程树中的 shell 进程，我们改用了一个 tini 这个来作为主进程，在基础镜像中添加 ENTRYPOINT [“/tini”, “—“] 即可，虽然不等子进程返回的方式可能不太优雅，但是可以快速 stop 容器带来的灵活性足以弥补这个缺点，当然特殊应用可以特殊处理。 Java 容器化问题Java 容器化的坑比较多，JDK 我们使用了 openjdk8(version “1.8.0_191”) ，jvm opts我们加上了-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.00，这个版本 java 已经可以正确获取到正确的 cpu 资源和内存资源，默认使用75%的cgroup空间为heap memory，留25%空间给 stack memory。防止因为heap memory加 stack memory 太大导致容器内存使用超出 Cgroup 限制被 Kill掉。 除此之外，我们还优化了随机数生成的原理： 1echo &quot;securerandom.source=file:/dev/urandom&quot; &gt;&gt; /usr/lib/jvm/default-jvm/jre/lib/security/java.security DNS perfermance（lookup failed）两方面原因： 一方面，docker 自身的 dns 允许并发数太低，已经提 issue并修复了：docker Increase max concurrent requests for DNS from 100 to 1024。 另一方面，musl的代码在dns解析的实现上有些问题，如果有ipv6的A记录那么解析性能不会出现问题，如果只有AAAA的ipv4记录，那么解析可能会出现卡死的情况，等待2.5s才返回，所以要添加一个break代码防止出现等待，在最新的 musl 的版本解决了(没有 发布，需要自行编译) 最后，这个问题其实是因为业务服务大多数是使用 http 短链接造成的，现在房多多已经全站使用 http2 长连接，这个瓶颈其实也就不存在了。 流量突然增高 slab分配失败导致机器负载高容器平台集群不定期的报slab memory malloc的错误 系统负载高时，服务器内核大量报slab cache错误，升级centos 7.5 新内核862解决。值得一提的是，在容器时代，大家对内核的要求越来越高也越来越依赖内核的功能，很多公司其实都走在了内核迭代的前列 发现了很多 bug 并对社区做出了贡献。 物理机配置问题导致容器网络不通我们有出现过一次交付物理机 restart network 后没有开启 ipv4_forward 导致的改物理机上的容器 overlay 网络挂的问题。 我们的解决方法是在启动容器前通过 ping 网关的方式检查 DNS服务和网络是否打通。 发布系统改造构建流程自定义在容器化的过程中，我们也把构建流程做了优化，引入了 jenkins pipeline 功能。Pipeline 对于我们的最重要的好处是可以把构建流程 DSL 代码化，并可以针对每一个项目自定义构建流程，当然我们有提供一个大体的框架，用户只需要更改自己所需要的就可以了，如下图: 最终会生成一个 jenkinsfile 并在每次构建的时候都回去调用项目对应的 jenkinsfile。有了这样的功能，开发就可以根据自己的需求，轻松的更改自己项目的构建流程。 Web Terminal我们根据业务开发的需求开发了 web 进入 docker 容器的功能。原理是转发 docker exec 命令到对应的物理机上，并转发输入输出。支持快捷键和高亮，体验良好。 Log日志我们通过在转发 docker logs 请求获取最新的2000条（默认，可配置）日志打印到 web 页面上，支持自动刷新和滚动。 日志收集我们会把项目输出的日志通过 volume 都挂载到每台宿主机的固定目录下，并用 global 模式部署 filebeat 进行采集，输出到我们的elastic集群上，然后在 elk 平台上查询日志。最近我们也在测试环境尝试 grafana loki 项目，他和 elastic 的原理相反，只索引必要的字段，可以节省大量的机器资源，如果是用来做”distribute grep”的话就很合适。 监控监控我们使用了 swarmprom 开源项目，监控项比较丰富，覆盖了机器基础指标，容器指标，可以较快的定位问题，当时当容器集群出现宕机等情况时，监控会暂时失效，所以我们在容器集群外也部署了针对机器的基础监控。具体效果如下： 推广容器的推广需要业务开发和业务运维的支持，不然很难推动。 推广首先要让开发和运维感受到红利： 容器相对于虚拟机更轻量化，可以实现秒级启动。 测试、预发布、线上的容器部署配置、环境 完全一致。 可以根据 CPU、内存或者 QPS 和延时快速扩容，提升服务能力。 服务 crash 会自动启动，自带高可用。 这四个特性的组合，可以给业务带来更大的灵活度和更低的计算成本。 我们团队是把这个容器平台当成一个产品来运作，业务开发就是我们的用户。 在推进容器化的过程中，我们还会做如下的事情： 通过培训让开发了解我们的产品优势（对比虚拟机）。 提供使用文档、接入文档等使得产品的易用度增加。 在迁移时给予开发更高优先级的支持。 资源尽量都加入容器集群，停止并减少虚拟机的供给。 总结从传统的虚拟机架构到现在的基于云原生的容器云架构，带来了秒级部署、秒级扩缩容、简化了CI/CD 流程、提供Service Mesh 微服务治理能力。 如果按虚拟机时代运维人肉调度服务，人肉管理资源，在新虚拟机部署一个新应用或者扩容一个应用的时间在10分钟以上，和现在的按秒计算时间是质的变化，这是招再多的业务运维人员也达不到的，无形中省去了很多人力成本。 通过容器云的落地，我们得到了一个面向服务的平台，把机器资源抽象，屏蔽了和发布无关的机器细节、部署细节，开发不用再了解自己的应用在哪一台物理机上面。运维也可以从茫茫多的管理表格中解脱出来，只需要关注集群利用率，添加机器资源即可。这样有利于公司 DevOps 的推行，提高开发效率和开发个体的创造力不再被运维限制，大大提升团队生产力。 对于我们运维开发团队来说，通过对Linux Kernel、Docker等优秀项目的优化工作，也获得了一些个人的提升。 接下来，我们还会根据自身的需求迭代服务治理、容器编排的功能，把管理集群的常规操作平台化，尽量做到日常操作可以不登录物理机去操作。 欢迎大家和我们一起探讨和交流，谢谢！","categories":[],"tags":[{"name":"container docker-swarm teamwork","slug":"container-docker-swarm-teamwork","permalink":"https://wangkai1994.github.io/tags/container-docker-swarm-teamwork/"}]},{"title":"2018思想汇报","slug":"2018review","date":"2019-02-11T15:06:13.000Z","updated":"2019-02-11T15:07:41.862Z","comments":true,"path":"2019/02/11/2018review/","link":"","permalink":"https://wangkai1994.github.io/2019/02/11/2018review/","excerpt":"2018是毕业的第二年的开始，我自认为毕业三年的成长最为关键，成长大于一切其他。也是2019的关键词。","text":"2018是毕业的第二年的开始，我自认为毕业三年的成长最为关键，成长大于一切其他。也是2019的关键词。2018年的前半年，在宁波云趣的工作其实挑战越来越少，需求总是处于我自认为目前体量做不了也没必要的状态，能做的又很少几乎很快就完成了。夏天的时候还出差去了一次西安体验了一次现场帮助公司解决银行客户问题和疑惑的经验。其实上半年一直在焦虑和思考自己的职业道路问题，自己的熟练语言选择是主 Python ，辅助 Go 和Java 了，技能数点的方向也是向 Devops发展了，转向传统的 Java后端 可以是可以，但是貌似不是我的兴趣所在了，在想是不是自己把自己的路走窄了，因为刚进云趣的时候老大就是各种给我拓展路子，什么都让我尝试。但是 Devops 貌似的确是我自己喜欢的方向，不用熟悉特定公司的商业业务，专注自动化等，所以说，找到自己的职业发展重心也是2018重要的收获之一。 在一段时间的犹豫以后，因为女朋友也早早去了上海，我就开始试水社招，看看自己的成色到底能去什么公司。修改了简历从后端转型 Devops 岗位或者叫运维开发岗位 中间件开发岗位之后，就开始了投简历。 说起来也是比较缘分，第一家投的公司就是房多多，约了视频面试，在一面结束后觉得要挂的时候，后面居然过了。其实事后星如哥也说个人水平面的都差不多，看在博客还可以就让我过了。其实我自己是觉得很慌的，后来只能拼命学习来让自己适应岗位的要求。 这次转型其实自己是非常感激，从后端到运维开发，从软件公司到了自己喜欢的互联网公司。大多数人都认为互联网工司并不是一个好选择，特别是互联网公司出来的。但是互联网公司的“随时倒闭“的危机感和用户基础、成长速度是数倍与其他公司的。就像开始所说，我给自己的目标就是成长，生活、加班和报酬其实不在我的期望之中，换言之就是可以为了成长来牺牲这些。但是现实情况还是 ok的，自己的老大很有效率，是那种用4分力做5分事的人，所以我的上班节奏一般也是9：30 - 19：30左右，其实不算多，但是还是挺累= = 算了一下其实最少每天也有10个小时呆在公司，但是强度对比其他人来说不算高，其他人应该会去吃个饭然后8.9点下班。但是和原先在宁波的工作区别很大，吃饭得花时间解决，不想花时间就得花钱来解决。但是很明显在上海，大家的生活节奏都是比较讲究效率，比较少的娱乐时间加大部分的学习时间，经常和女朋友开玩笑说大马路上随便拉一个外卖小哥都有理想以及上进心。 在这种环境下，再加上换公司的 buff，我的技术栈在下半年也拓宽了许多，在原先后端程序员的基础上又继续点了云原生的技能树： 容器，Docker api，Docker 原理(cgroup,namespace)，Dockerfile 优化，docker build 优化 容器编排相关，Docker Swarm api、原理，分布式系统，k8s api 和资源。 容器网络，macvlan ,overlay 以及实现 企业容器化时代的 CI/CD流程，一个方便融合其他系统的发布系统，Devops 平台。Pipeline。 监控相关，exporter 编写，基于 CMDB 自动发现配置。监控收敛，数据分析。监控体系的思考。APM tracing 相关。grafana 面板编写。主要还是理解 promethus 的思想。 跳板机的二次开发，ssh 协议、 tty 理解。 完整的企业容器技术栈的搭建、从虚拟机迁移到容器的推动经验。 Service Mesh 的学习和协助实践，envoy 作为网关的 api 和原理。 云原生的思想理解 Go语言编程实践 罗列下来尝试过的东西还是挺多的（边际效应），2019年的目标也挺多。 1.熟练 k8s api ，熟悉思想和原理 2.docker 原理和 api 在公司分享。 3.推广发布系统的使用 4.熟练 Go 5.k8native 生态 6.自动化，自动化，自动化 7.云计算开发技能树点起来 2018也是 wow 的一年，19年继续！","categories":[],"tags":[]},{"title":"运维的思维升级-不可变基础设施","slug":"Immutable-Infrastructure","date":"2019-01-12T10:43:25.000Z","updated":"2019-01-14T01:54:23.755Z","comments":true,"path":"2019/01/12/Immutable-Infrastructure/","link":"","permalink":"https://wangkai1994.github.io/2019/01/12/Immutable-Infrastructure/","excerpt":"运维的思维升级-不可变基础设施不可变基础设施（Immutable Infrastructure）是云原生的应用之一，常见的微服务、Service Mesh、容器、声明式API都是可以说是云原生应用。云原生是一个比较抽象的概念，甚至 CNCF 自己也因为其发展速度之快，对定义有过很多次更改。","text":"运维的思维升级-不可变基础设施不可变基础设施（Immutable Infrastructure）是云原生的应用之一，常见的微服务、Service Mesh、容器、声明式API都是可以说是云原生应用。云原生是一个比较抽象的概念，甚至 CNCF 自己也因为其发展速度之快，对定义有过很多次更改。 云原生的定义云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。 什么是不可变基础设施在我们原先（现在还存在）的运维方式里，我们会用物理机或者虚拟机去安装操作系统、逐个上传代码部署业务应用、SSH 连接服务器、手动升级降级软件包的版本。总的来说当基础设施创建以后，它是会被经常更改的，这些物理机或者虚拟机在我的概念里都是 “可变的基础设施”、我从开发的角度认为它是非常传统和手工作坊的感觉。 那相反来说，就可以想象出一个不可变的基础设施应该是怎么样的：在一个基础设施被创建以后，是不接受任何方式的更新的，这个基础设施也可以作为范本不断的扩展成 N 个。如果需要更新修改默认的内容，应该先去修改对应的公共的配置，构建新的服务器，然后替换全部旧的服务器。简单的来说就是：旧的不去新的不来 : ) 不可变基础设施的优势在于更高的一致性和可靠性，创建、部署的过程也是可预测的。还可以避免Configuration Drift（配置漂移，为了解决某个业务特定问题，为某一个服务器安装了一个库等，然后出现了换一个环境应用起不来的情况）、Snowflake Servers（雪花服务器：管理一堆服务器，手动登陆每台服务器，手动安装众多软件，手动修改各种配置文件，导致每台服务器如同雪花一样独特，各服务器配置千差万别难以复制。）等等。 可变和不可变基础设施之间的差异可变基础和不可变基础设施之间最根本的区别在于它们的核心理念：前者旨在在部署后进行更改; 后者旨在保持不变并从根本上进行替换。 Randy Bias提出过一个很有意思的”宠物与牛”概念：传统的可变的基础设施是不可以随便替代的，它们像宠物一样：每一个对你来说都是独一无二的、无法模仿的、自己一手养大的、如果”死了”对你的打击是毁灭性的；可变的基础设施则是相反，它是一次性的、它是很容易通过自动化设施来横向扩展的，它们是一个牛群，没有一个是独一无二或者不可或缺的。 他的原话： 在旧的做事方式中，我们将服务器视为宠物，例如Bob是一个邮件服务器。如果Bob损坏了，那就全都要靠手动的了。那么首席执行官也就无法收到他的电子邮件了，这无异于是世界末日。但如果以新的方式，服务器会被编号，就像牛群中的牛一样。例如，www001到www100。当一台服务器发生故障时，它会被取回，射击并在线路上更换。 其实《凤凰项目》这本书里面的 Phoenix 服务器 是一个非常优美的比喻，当我们的基础设施有一天（或者说每时每刻）变成了灰烬，他可以优雅的从头开始构建一个新的服务器。与之对应就是雪花服务器，手工管理，经常更新、形成一个独特的环境。 不可变基础设施的优势提升发布应用效率基于不可变基础设施的部署都是可以由代码设定的，类似于Dockerfile，这样就可以很简单的用上 git 等版本控制来维护环境。部署应用也不会再依赖服务器之前的状态，在本地能起来，在线上也能起来。很少会出现 “Not Work On My Machine”这样的问题，现在业务开发来私聊我线上应用起不来的问题，我会很有信心的和他说是他的代码问题而不是环境问题。 没有雪花服务器我可以允许你登录服务器进行一些 debug，查看日志的操作，但是我知道随便你怎么更改都是无效的，下一次启动就会完全还原，完全不担心。需要更改？请修改配置基础设施的代码。 快速水平扩展因为所有服务器都是用同一份配置代码生成，只要有资源，我可以很简单的通过更改副本数就可以完成水平扩展，而非手忙脚乱的开机器、登录、做变更操作。 简单的回滚和恢复我可以通过基础设施配置代码的版本控制来快速的回滚到上一个版本，不管你装了多少新的依赖、新的库，对我来说都是一样的。大大缩短了恢复的时间。 房多多的不可变基础设施实施细节已完成： 业务项目 Docker化 利用 Docker 环境来build Docker Image CI/CD 流程全部 Pipeline 化，代码化 利用 Portainer,Docker Swarm 搭建面向服务的架构 业务项目尽量无状态化 待完成： 持久的数据层：集中式的日志保存、有状态服务的存储 底层物理机的不可变基础设施化：Code as Infrastructure 业务开发的运维都理解这层思想，少用 SSH，本地调试而非线上调试 结论本文是想在运维团队中科普云原生中很重要的基础设施不可变的思想、统一思想。对比了旧式的可变基础设施架构的概念和实际差异、使用它的优势以及实现的详细信息。 相信看完以后大家都会觉得这是一个正确路子，只要方向正确，我们的努力就不会白白浪费！ 参考文档：https://www.digitalocean.com/community/tutorials/what-is-immutable-infrastructure 推荐听一下在一个基础设施良好的公司的开发体验：http://codetimecn.com/episodes/devops_tooling","categories":[],"tags":[{"name":"devops","slug":"devops","permalink":"https://wangkai1994.github.io/tags/devops/"}]},{"title":"监控系统整理和体系化监控思考","slug":"monitor","date":"2019-01-08T15:08:13.000Z","updated":"2019-01-09T12:59:22.652Z","comments":true,"path":"2019/01/08/monitor/","link":"","permalink":"https://wangkai1994.github.io/2019/01/08/monitor/","excerpt":"监控系统整理和体系化监控思考监控是 Devops 中不可或缺的一环，也是运维工作，处理问题排查问题的重要工具，几乎天天会用到。 在房多多现有的监控实践中，我们总是会发现出现一个问题后，会很难去真正排插出问题所在及影响范围，经常需要在各个监控程序之间切换来找到联系；在系统崩溃前，也没有预警来提示风险；在有规律的大流量来临前，没有相关提示要求扩容。 房多多的监控软件基本是完善的，总结整理如下：","text":"监控系统整理和体系化监控思考监控是 Devops 中不可或缺的一环，也是运维工作，处理问题排查问题的重要工具，几乎天天会用到。 在房多多现有的监控实践中，我们总是会发现出现一个问题后，会很难去真正排插出问题所在及影响范围，经常需要在各个监控程序之间切换来找到联系；在系统崩溃前，也没有预警来提示风险；在有规律的大流量来临前，没有相关提示要求扩容。 房多多的监控软件基本是完善的，总结整理如下： 基础监控： ​ 数据库监控：zabbix ​ 网络设备监控：zabbix ​ 机器资源监控：promethus node_exporter ​ 主机硬件监控：promethus node_exporter,zabbix ​ ping 监控：promethus world_ping ​ dns 监控：promethus world_ping ​ OS 性能： 业务监控： ​ 日志监控：snowman,filebeat ​ 端口监控：promethus consul_exporter ​ HTTP 服务拨测：promethus blackbox ​ 用户主观反馈： ​ 用户访问质量：ELK APM ​ 调用关系监控：ELK APM, PINGPOINT 数据利用： ​ 告警分级：promethus alertmanager、zabbix 告警 ​ 告警关联收敛： ​ 故障自愈： ​ 审计、报表： 方法论想要洞悉监控，应该先理清一些概念。 监控的定义：通过技术手段发现服务异常，持续优化业务可用性与用户体验。 监控的方式： ​ 主动 程序埋点。 ​ 被动，从外部观察，黑盒检测。 ​ 旁路，与程序逻辑无关，对口碑和服务质量进行监控。 监控的类型： ​ 基础监控：IAAS 层（服务器，网络，系统指标，硬盘等） ​ 业务监控： ​ 服务端监控：服务调用链监控 ​ 客户端监控：APP，网站等直接与用户接触 监控的实现原则：​ 指标全面，覆盖所有监控类型。 ​ 部署容易，轻，稳定性高，侵入性小。 ​ 智能分析、收敛，监控对象收敛。 监控的本质： ​ 运维、开发、测试这三个角色应该视角统一，共同保证可靠性-&gt;可用性-&gt;用户体验。 监控的目的： ​ 持续优化业务服务质量，并建设质量体系。 从产品角度看监控当我们站在使用者去开发监控时，我们会下意识的去针对缺失的监控软件进行补全，这可以称之为点。那么让我们换一个角度，当我们去用建设者这个视角去看监控是怎么样的呢，我想到的是抽象，在抽象的基础上去构建功能。那么一个业务监控应该如何抽象呢？监控作为一个数据类的产品，当然也可以有这样的闭环：数据抓取-&gt;数据增值-&gt;数据消费。 数据抓取：利用工具抓取尽量多和有用的，直接可以取到的数据。 数据增值：把收集来的 N 多数据进行聚合，变成高阶数据；把相似的数据聚合； 数据消费：把数据图形化展示，做成 UI，尽量方便用户获取他们感兴趣的东西。设置阈值，产生告警；计算服务高峰期等等。 监控体系体系：泛指一定范围内或同类的事物按照一定的秩序和内部联系组合而成的整体，是不同系统组成的系统。 我们需要把相互独立的一套套监控系统通过内部交互来形成一个大的整体，而非一个个的数据孤岛。其实从上文可以得出总结，监控体系可以从产品角度建立，在闭环的基础上，打通各个系统，把每个系统的数据面抓取、数据增值、数据消费给按层次统一。这样就比较容易建立起一个监控体系。 总结写本文主要也是想让自己理清思路。在前期堆了一大堆监控后，需要理一理后面的方向，建立起监控体系的思维逻辑，从有到有用，后面应该还会写一些应用监控的建立方法论。","categories":[],"tags":[{"name":"devops","slug":"devops","permalink":"https://wangkai1994.github.io/tags/devops/"}]},{"title":"iptables","slug":"iptables","date":"2018-09-16T10:41:41.000Z","updated":"2018-09-17T16:01:14.794Z","comments":true,"path":"2018/09/16/iptables/","link":"","permalink":"https://wangkai1994.github.io/2018/09/16/iptables/","excerpt":"iptables在熟悉 linux 系统之前，只是含糊的指导 iptables 和防火墙相关，这次在学习 docker swarm 等原理时接触到了，故进行总结。 iptables 是运行在User space 的软件（非kernel space），通过空值 Netfilter （位于kernel space）来管理网络数据包的流动和传送，网络地址转换，数据包过滤等防火墙功能。 iptables 的表iptables 包换五张表，raw、filter、nat、mangle 和security。 raw 用于配置数据包， raw 中的数据包不会被系统跟踪。 filter 是用于存放所有与防火墙相关操作的默认表。 nat 用于 网络地址转换（例如：端口转发）。 mangle 用于对特定数据包的修改（参考损坏数据包）。 security 用于强制访问控制 网络规则 规则名称 raw filter nat mangle security PREROUTING 是 是 是 INPUT 是 是 是 是 OUTPUT 是 是 是 是 POSTROUTING 是 是 FORWARD 是 是 是 是","text":"iptables在熟悉 linux 系统之前，只是含糊的指导 iptables 和防火墙相关，这次在学习 docker swarm 等原理时接触到了，故进行总结。 iptables 是运行在User space 的软件（非kernel space），通过空值 Netfilter （位于kernel space）来管理网络数据包的流动和传送，网络地址转换，数据包过滤等防火墙功能。 iptables 的表iptables 包换五张表，raw、filter、nat、mangle 和security。 raw 用于配置数据包， raw 中的数据包不会被系统跟踪。 filter 是用于存放所有与防火墙相关操作的默认表。 nat 用于 网络地址转换（例如：端口转发）。 mangle 用于对特定数据包的修改（参考损坏数据包）。 security 用于强制访问控制 网络规则 规则名称 raw filter nat mangle security PREROUTING 是 是 是 INPUT 是 是 是 是 OUTPUT 是 是 是 是 POSTROUTING 是 是 FORWARD 是 是 是 是 iptables 命令$ iptables [-t 表名] 命令选项［链名]［条件匹配］[-j 目标动作或跳转］ 理解 iptables 规则1234567$ iptables -L -vChain INPUT (policy ACCEPT 350K packets, 63M bytes) pkts bytes target prot opt in out source destinationChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destinationChain OUTPUT (policy ACCEPT 18M packets, 1916M bytes) pkts bytes target prot opt in out source destination 每条链中都可以添加多条规则，规则是按照顺序从前到后执行的。我们来看下规则的表头定义。 pkts：处理过的匹配的报文数量 bytes：累计处理的报文大小（字节数） target：如果报文与规则匹配，指定目标就会被执行。 prot：协议，例如 tdp、 udp、 icmp 和 all。 opt：很少使用，这一列用于显示 IP 选项。 in：入站网卡。 out：出站网卡。 source：流量的源 IP 地址或子网，后者是 anywhere。 destination：流量的目的地 IP 地址或子网，或者是 anywhere。 还有一列没有表头，显示在最后，表示规则的选项，作为规则的扩展匹配条件，用来补充前面的几列中的配置。 prot、 opt、 in、 out、 source 和 destination 和显示在 destination 后面的没有表头的一列扩展条件共同组成匹配规则。当流量匹配这些规则后就会执行 target。 关于 iptables 规则请参考常见iptables使用规则场景整理。 target 支持的类型 target 类型包括 ACCEPT 、REJECT、 DROP、 LOG 、 SNAT、 MASQUERADE、 DNAT、 REDIRECT、 RETURN 或者跳转到其他规则等。只要执行到某一条链中只有按照顺序有一条规则匹配后就可以确定报文的去向了，除了 RETURN 类型，类似编程语言中的 return 语句，返回到它的调用点，继续执行下一条规则。 target 支持的配置详解请参考 iptables 详解（1）：iptables 概念。 从输出结果中可以看到 Init 容器没有在 iptables 的默认链路中创建任何规则，而是创建了新的链路。 查看 iptables nat 表中注入的规则12345678910111213141516171819202122232425262728293031323334353637383940414243# 查看 NAT 表中规则配置的详细信息$ iptables -t nat -L -v# PREROUTING 链：用于目标地址转换（DNAT），将所有入站 TCP 流量跳转到 ISTIO_INBOUND 链上Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 2 120 ISTIO_INBOUND tcp -- any any anywhere anywhere# INPUT 链：处理输入数据包，非 TCP 流量将继续 OUTPUT 链Chain INPUT (policy ACCEPT 2 packets, 120 bytes) pkts bytes target prot opt in out source destination# OUTPUT 链：将所有出站数据包跳转到 ISTIO_OUTPUT 链上Chain OUTPUT (policy ACCEPT 41146 packets, 3845K bytes) pkts bytes target prot opt in out source destination 93 5580 ISTIO_OUTPUT tcp -- any any anywhere anywhere# POSTROUTING 链：所有数据包流出网卡时都要先进入POSTROUTING 链，内核根据数据包目的地判断是否需要转发出去，我们看到此处未做任何处理Chain POSTROUTING (policy ACCEPT 41199 packets, 3848K bytes) pkts bytes target prot opt in out source destination# ISTIO_INBOUND 链：将所有目的地为 9080 端口的入站流量重定向到 ISTIO_IN_REDIRECT 链上Chain ISTIO_INBOUND (1 references) pkts bytes target prot opt in out source destination 2 120 ISTIO_IN_REDIRECT tcp -- any any anywhere anywhere tcp dpt:9080# ISTIO_IN_REDIRECT 链：将所有的入站流量跳转到本地的 15001 端口，至此成功的拦截了流量懂啊 Envoy Chain ISTIO_IN_REDIRECT (1 references) pkts bytes target prot opt in out source destination 2 120 REDIRECT tcp -- any any anywhere anywhere redir ports 15001# ISTIO_OUTPUT 链：选择需要重定向到 Envoy（即本地） 的出站流量，所有非 localhost 的流量全部转发到 ISTIO_REDIRECT。为了避免流量在该 Pod 中无限循环，所有到 istio-proxy 用户空间的流量都返回到它的调用点中的下一条规则，本例中即 OUTPUT 链，因为跳出 ISTIO_OUTPUT 规则之后就进入下一条链 POSTROUTING。如果目的地非 localhost 就跳转到 ISTIO_REDIRECT；如果流量是来自 istio-proxy 用户空间的，那么就跳出该链，返回它的调用链继续执行下一条规则（OUPT 的下一条规则，无需对流量进行处理）；所有的非 istio-proxy 用户空间的目的地是 localhost 的流量就跳转到 ISTIO_REDIRECTChain ISTIO_OUTPUT (1 references) pkts bytes target prot opt in out source destination 0 0 ISTIO_REDIRECT all -- any lo anywhere !localhost 40 2400 RETURN all -- any any anywhere anywhere owner UID match istio-proxy 0 0 RETURN all -- any any anywhere anywhere owner GID match istio-proxy 0 0 RETURN all -- any any anywhere localhost 53 3180 ISTIO_REDIRECT all -- any any anywhere anywhere# ISTIO_REDIRECT 链：将所有流量重定向到 Envoy（即本地） 的 15001 端口Chain ISTIO_REDIRECT (2 references) pkts bytes target prot opt in out source destination 53 3180 REDIRECT tcp -- any any anywhere anywhere redir ports 15001 iptables 显示的链的顺序，即流量规则匹配的顺序。其中要特别注意 ISTIO_OUTPUT 链中的规则配置。为了避免流量一直在 Pod 中无限循环，所有到 istio-proxy 用户空间的流量都返回到它的调用点中的下一条规则，本例中即 OUTPUT 链，因为跳出 ISTIO_OUTPUT 规则之后就进入下一条链 POSTROUTING。 ISTIO_OUTPUT 链规则匹配的详细过程如下： 如果目的地非 localhost 就跳转到 ISTIO_REDIRECT 链 所有来自 istio-proxy 用户空间的流量跳转到它的调用点 OUTPUT 继续执行 OUTPUT 链的下一条规则，因为 OUTPUT 链中没有下一条规则了，所以会继续执行 POSTROUTING 链然后跳出 iptables，直接访问目的地 如果目的地是 localhost 但是流量又不是来自 istio-proxy 用户空间的就跳转到 ISTIO_REDIRECT 链","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://wangkai1994.github.io/tags/linux/"}]},{"title":"鹰眼监控实现","slug":"old-hawkeye-design","date":"2018-05-28T14:49:17.000Z","updated":"2019-01-17T06:55:07.960Z","comments":true,"path":"2018/05/28/old-hawkeye-design/","link":"","permalink":"https://wangkai1994.github.io/2018/05/28/old-hawkeye-design/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"2017总结","slug":"2018","date":"2018-02-19T16:15:11.000Z","updated":"2018-02-19T16:16:38.903Z","comments":true,"path":"2018/02/20/2018/","link":"","permalink":"https://wangkai1994.github.io/2018/02/20/2018/","excerpt":"时间过得真的快啊，又是一年一度的个人思想汇报的时间了。为什么一直选在除夕的晚上呢，因为过年的意义除了和家人团聚，还有就是可以安静下来想想过去一年过的怎么样。","text":"时间过得真的快啊，又是一年一度的个人思想汇报的时间了。为什么一直选在除夕的晚上呢，因为过年的意义除了和家人团聚，还有就是可以安静下来想想过去一年过的怎么样。2017年我离开了实习的万朋，和部门老大聊离职的时候，老大说万朋是个不错的起点，我也觉得以我的水平来说，虽然不及互联网公司去实习来的有挑战性和提高，但是未必去互联网公司适合我的技术。在一个软件公司，通过大量重复操作，更加会推动自己去了解框架的底层技术，了解为什么那么写？公司里封装好的框架也适合参考这去模仿大神的写法。时间也差不多，呆了半年，基本上来说是工作，回家，学习看书，参加笔试面试。在2017的开始我进入了现在的公司云趣，起初的想法是有点对自己丧失信心，不知道是不是应该回去宁波。偶然在 v2上看到了一家符合我心意的公司（创业公司，大牛坐镇，老板 nice，氛围轻松），面试也非常轻松，就加入了云趣。这次加入迫使我开始学习新的技术栈 Python，其实如在上面所说的，大量的重复工作让我反复思考，能不能不写那么多 CRUD 的模板代码？学习了 Django 发现，的确是我那时候想要的一种东西，完美简单的 ORM，活跃的生态。简洁的 Python 语言，简直是解放生产力的工具啊！这时出现了第一个我要感谢的人就是金镝哥。金镝哥是原先一号店的程序员，各种神，且热爱看书。他教会了我学习的方法，从 Django 开始。还给我们讲解了 effective java 这本好书，Django 的开发方法论等等，还时不时的推荐了各种好用的工具，也潜移默化的教会了我们很多处理问题的方法。我在熟练了 Django 以后，公司里来了前端实习生金星，开始了前后端分离的开发。发现不用写前端的 js 之后，感觉整个生产力都被解放了出来，可以专心研究如何写业务啦！随后的事情开始变得有些坎坷，金镝哥回了武汉找了工作，公司也就变成了只有我一个人。sid 哥也不在公司坐镇，感觉公司少了很多工作的氛围，还好有 sid 哥粗暴的风格来推动着我们前进，陆续也完成了执行平台和新鹰眼的开发。个人方面，如前面所说，技术栈从 Java 转型到了Python，在学习 python 的过程中接触到了很多网络和操作系统层面的东西，可能很多东西从学习 Python 开始才了解到为什么要这样去做。然后自己想的事情也发生了改变，其实技术对一个产品的影响到底占了多少比例呢？当我们在谈论一个商业上成功的产品时我们到底在讨论什么？我也越来越好奇心理学和认知对个人生产力带来的解放，开始好奇历史因为可以以史为鉴，开始对宗教有一些自己的看法和认知。2017年开始意识到了有规律读书的重要性，艰难的看完了人类简史，失乐园，流畅的 Python，unix 网络编程等书，的确是挺遗憾的一件事情，没有看足够多的书。书是可以支撑起自我价值观并可以逻辑自洽的基础，大家都说大学里买的技术书的金额等于第一个月工资，相信也同样适用在工作中。2017年发生的事情太多太多站开来可以说好多好多，我觉得讲遗憾是对2017前最好的总结，遗憾没有看更多的好书，遗憾没有配戴佩倩去更多地方，遗憾不会弹吉他。希望2018更加顺利，继续可以让自己在年底 wow 一下！","categories":[],"tags":[]},{"title":"Django 2.0 升级记","slug":"django2-0","date":"2018-01-03T03:54:41.000Z","updated":"2018-02-19T16:17:00.737Z","comments":true,"path":"2018/01/03/django2-0/","link":"","permalink":"https://wangkai1994.github.io/2018/01/03/django2-0/","excerpt":"看到 Django 终于从2.0到了2.0.1，感觉大家坑应该都踩的差不多了，那我们也可以开始升级啦。","text":"看到 Django 终于从2.0到了2.0.1，感觉大家坑应该都踩的差不多了，那我们也可以开始升级啦。 首先 1pip install django==2.0.1 然后依旧是 runserver，马上出现了错误： 123 File &quot;/Users/wangkai/Desktop/workspace/hawkeye-v2/restful/hawkeye/authx/models.py&quot;, line 64, in User owner = models.ForeignKey(&apos;User&apos;, null=True, blank=True)TypeError: __init__() missing 1 required positional argument: &apos;on_delete&apos; 看了官方的说明： 1The on_delete argument for ForeignKey and OneToOneField is now required in models and migrations. Consider squashing migrations so that you have fewer of them to update. 补全了 on_delete，然后来到了 12raise ImproperlyConfigured(&quot;Cannot import channel routing %r: %s&quot; % (routing, e))django.core.exceptions.ImproperlyConfigured: Cannot import channel routing &apos;hawkeye.routing.channel_routing&apos;: No module named &apos;django.core.urlresolvers&apos; 升级djangorestframework: 1pip install djangorestframework==3.7.7 解决了一些升级djangorestframework后出现的引用问题 然后修改 各种urls.py，不过似乎正则 url 的方式还是支持的。 1234old:url(r&apos;^api/$&apos;, include(&apos;api.urls&apos;, namespace=&apos;api&apos;)),new:url(&apos;api/&apos;, include(&apos;api.urls&apos;)), ok，升级到此结束，接下来就开始测试踩坑。","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"https://wangkai1994.github.io/tags/Django/"}]},{"title":"git","slug":"git","date":"2017-10-10T08:16:53.000Z","updated":"2017-10-10T08:18:08.640Z","comments":true,"path":"2017/10/10/git/","link":"","permalink":"https://wangkai1994.github.io/2017/10/10/git/","excerpt":"","text":"Git 笔记删除上一次的 commitgit log 查看上上一次的的 commit id git reset -soft","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://wangkai1994.github.io/tags/git/"}]},{"title":"Oracle 分享 记录","slug":"20170503","date":"2017-05-03T07:51:48.000Z","updated":"2017-05-03T07:55:26.000Z","comments":true,"path":"2017/05/03/20170503/","link":"","permalink":"https://wangkai1994.github.io/2017/05/03/20170503/","excerpt":"基础知识因为以前对 SQL 的细节都不太熟悉，所以先搜索了一些最基础的信息： 什么是 Oracle database: Oracle Database，又名Oracle RDBMS，甲骨文公司开发的关系型数据库。 Oracle 数据库与 Mysql 的架构区别：","text":"基础知识因为以前对 SQL 的细节都不太熟悉，所以先搜索了一些最基础的信息： 什么是 Oracle database: Oracle Database，又名Oracle RDBMS，甲骨文公司开发的关系型数据库。 Oracle 数据库与 Mysql 的架构区别： 1.Oracle ​ 数据文件包括：控制文件、数据文件、重做日志文件、参数文件、归档文件、密码文件。这是根据文件功能进行划分，并且所以文件都是二进制编码后的文件，对数据库算法效率有极大的提高。由于有了文件管理的统一性，就可以对 SQL 执行过程中的解析和优化，指定统一的标准：RBO(基于规则的优化器)、CBO（基于成本的优化器） 通过优化器的选择，以及无敌的 HINT 规则，给予了 SQL 优化极大的自由，对 CPU、内存、IO 资源进行方方面面的优化。 2.Mysql ​ 最大的一个特色，就是自由选择存储引擎。每一个表都是一个文件，都可以选择合适的存储引擎。常见的引擎有 InnoDB、MyISAM、NDBCluster 等。但由于这种开放插件式的存储引擎，比如要求数据库与引擎之间的送耦合关系。从而导致文件的一致性大大降低。再 SQL 执行优化方面，也就有着一些不可避免的瓶颈。再多表关联、子查询优化、统计函数等方面是软肋，而且只支持极简单的 HINT。 什么是HINT：在大多数的数据库实现中，hint 是一种SQL标准的补充，去告诉数据库引擎如何去执行一条查询语句。比如，一个 hint 可以告诉数据库引擎是不是去用索引。 RBO与CBO：RBO (Rule-Based Optimization)基于规则的优化、CBO(Cost-Based Optimization) 基于代价的优化。 在较早的 Oracle 版本中，Oracle 是采用基于规则的优化，比如在规则中，索引的优先级大于全表扫描，那在查询某张有索引的表的时候，就一定使用索引。简单粗暴，但是很多情况下就会不试用，因为规则太不灵活了，如果数据变了可能就不再适用。在 9i 版本出来的时候，Oracle 就推荐使用 CBO。 CBO是一种比RBO更加合理、可靠的优化器，它是从ORACLE 8中开始引入，但到ORACLE 9i 中才逐渐成熟，在ORACLE 10g中完全取代RBO， CBO是计算各种可能“执行计划”的“代价”，即COST，从中选用COST最低的执行方案，作为实际运行方案。它依赖数据库对象的统计信息，统计信息的准确与否会影响CBO做出最优的选择。如果对一次执行SQL时发现涉及对象（表、索引等）没有被分析、统计过，那么ORACLE会采用一种叫做动态采样的技术，动态的收集表和索引上的一些数据信息。 CBO优化器根据SQL语句生成一组可能被使用的执行计划，估算出每个执行计划的代价，并调用计划生成器（Plan Generator）生成执行计划，比较执行计划的代价，最终选择选择一个代价最小的执行计划。查询优化器由查询转换器（Query Transform）、代价估算器（Estimator）和计划生成器（Plan Generator）组成。 提到的一些概念集群：share everything（缓存） , mysql 那种是 share nothing（mpp架构），Oracle RAC(Oracle Real Application Clusters) 如何判断有没有负载：顶级活动 如何判断哪一句 SQL 需要做优化：TOP sql 的运行时间，CPU 占用率，这些数据 Oracle 都会记录再表中，不用自己去打点搜集，但是保存时间不会很长（一周），所以一些数据还是需要保存在监控系统的 PostgreSQL中（三个月）。 如果做优化：并行执行的概念(hash分配，广播分配等等)…http://www.oracle.com/technetwork/cn/articles/database-performance/parallel-execution-2417440-zhs.pdf 、设置很大的值来强制 RBO 不使用嵌套循环（估算值，实际值） db time 可能大于实际的时间，因为会有并行运算的存在。 使用并行运算以后，最好的情况下时间会大于倍数的减少。 感想理解到了为什么 mysql 安装只有几百 M,而 Oracle 需要几 G，其实是Oracle提供了很多方便监控数据库，优化 sql 查询的方法 等等等等。这次科普以后，后续会去补充一些 Oracle 数据库的基础知识和视频来继续探索 Oracle。","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://wangkai1994.github.io/tags/数据库/"}]},{"title":"解决 image not found 问题","slug":"20170428","date":"2017-04-28T09:27:20.000Z","updated":"2017-04-28T09:27:55.000Z","comments":true,"path":"2017/04/28/20170428/","link":"","permalink":"https://wangkai1994.github.io/2017/04/28/20170428/","excerpt":"","text":"原链接：http://stackoverflow.com/questions/19776571/error-dlopen-library-not-loaded-reason-image-not-found 在 mac os(os x) 下去引用包的时候会出现很多问题。当直接用 dlopen打开一个绝对路径的 library 时一般是没有问题的。但是如果你加载了一个 library ，同时里面还需要加载另外的包的时候，你就会遇到加载不上的问题。 解决的方法有几个。你可以在你跑程序之前去配对应的环境变量，这就相当于在动态加载时告诉程序去哪儿找需要的lib，但是这不是一个好办法。 每当一个动态库被创建的时候都会有一个 install name，这个名字会包含在二进制文件里面，可以被 otool 命令查看到，otool -L mach-o_binary 会找到虽有包含在里面的动态库。当一个动态库被静态的链接到其他可执行的文件时（二进制文件或者 dylib），它预想的路径可能是一个相对的路径从而会在你的系统上找不到。 另一个解决办法就是install_name_tool，他可以修改预先设定好的路径， It can be run against the dylib before it gets statically linked against (in which case you have nothing left to do), or it can be run against the executable that loads it in order to rewrite those expectations. 例子install_name_tool -change /usr/lib/libphys-services.dylib @rpath/lib/libphys-services.dylib phys_services.so. 相关概念：System Integrity Protection，spawed process","categories":[],"tags":[]},{"title":"20170420周记","slug":"20170421","date":"2017-04-20T13:25:10.000Z","updated":"2017-05-31T13:27:06.000Z","comments":true,"path":"2017/04/20/20170421/","link":"","permalink":"https://wangkai1994.github.io/2017/04/20/20170421/","excerpt":"","text":"从上一家公司结束以后，好像就丢了写日报/周报这个比较好的习惯。试过几次把培训的内容和学习的内容发到 blog，但是总会有一些拖延症，so 还是写周报/日报吧！这周的工作开始与写一个 sql lab的后端接口，用来接受 sql语句并返回查询结果，需要考虑到的几个点有 支持大多数 数据库，动态切换数据源。用什么来写呢，有三种选择：第一种是 spring boot+data(JPA)，Spring全家桶总是让人感觉很稳健，而且 JDBC对数据库支持的数量也是令人方向的，嗯不错，作为备选方案吧；第二种是 Flask+sqlAlchemy，调研发现 Flask算是比较‘轻’的 Python 框架，算是 Micro Framework，也更加 Pythonic和灵活，也适合像我这种 python初学者。sqlAlchemy也是好评如潮的 Python orm之一 支持的数据库也很齐全，database url 也非常适合用来维护数据源。第三种，django orm，试用了一下就对前面的方法说88了，为什么？因为试用了下就实现了需求啊……Flask 以后见~接下来还遇到几个问题： 需要跑多句 sql：sql一般都以分号结尾，那我就直接做一个 split 然后遍历执行 sql语句，按index加到需要返回的 JsonResponse里面就暂时解决了，不知道后面会不会有坑。 原来使用的request.GET[‘param’] 会有问题，换成 request.GET.get(‘param’)才对。 以前没有真正的写过前后端分离的代码，和前端对接的时候就会发现很多问题，比如跨域问题，详细见 bloghttp://wangkai1994.github.io/2017/04/15/20170415/ 切换数据源问题：一开始想的很复杂，想怎么把自己的 数据源Model 的数据加载到 settings里去，查了很久，后来突然想到 settings就是一个 Model啊，修改 database的值不就完了嘛。于是就有了想法，维护一个数据源 Model，里面含 URL。需要切换时，使用的时候用dj_database_url这样一个app来把 database url 解析成一个 Settings里可以正确使用的 dict，赋值给 Settings就 ok。尝试了一下，没有问题。搜索一上午，解决5分钟。 那天解决以后洗澡时突然想到，如果一个人切换了settings里的 database，第二个人也在同时执行查询就会出现问题。所以修改了解决方案，数据源需要随着 sql 查询的请求发过来，每次查询结束以后把定义的数据源清空。这样又出现了另外的一个问题，需要考虑加互斥锁，不然同时操作时一定会出现数据源变化的问题，解决。 其他的学习和ideas： 只是听过 Restful api，这次真的需要写了就不知如何下手，花了时间补习了https://cn.udacity.com/course/designing-restful-apis–ud388，然后快速的过了遍 django-restful-framework 的 Tutorial，意思是 restful接口的增删改差它也能帮你生成一套，简直丧心病狂。 接口需要做身份验证，如果在后台判断登录状态的话那这个接口就是带状态了（突然就理解了为什么要把接口无状态化）。每次传 password和 username反人类也不安全，所以就使用了 token。调研了 token怎么用方便以后，选择了rest_framework_jwt。搜索一下午，实现5分钟 again。。。。 搞了搞 spring boot 和 data 的 demo，已经有点感觉不舒服了。 思考了下以往学习的规律，觉得自我学习也不应该太自由，不然容易学了几天就跑去学别的东西，需要有计划性并持之以恒的学习一段时间才会有效果。这次的 Django+python的学习还是持续了一个多月已久，下次的学习一定要给自己定个计划，没有完成加班也要完成。 听了罗振宇的一个思想觉得很有道理：很多毕业生刚进入职场以后往往还是带有一种“考场思维”，觉得上司给任务就是一个考试，如果任务完成如果不夸夸你就很没动力等等症状。但是，职场任务和考试最大的区别是，你可以抄啊！！最近一直面向stackoverflow 编程的我深有体会，人家代码比你实现的优雅为什么不抄呢。还有就是需要会求助他人，可能一个问题你憋了一上午别人一说你就懂了，你成长快速对公司也是好事。工作不是考场，需要把互相协作的优势发挥出来，一起把任务完成的又快又好才是老板想看到的，不会在意你是自己造轮子啊还是怎么实现的。","categories":[],"tags":[]},{"title":"理解和解决前后端分离出现的跨域问题","slug":"20170415","date":"2017-04-15T06:26:39.000Z","updated":"2017-04-15T07:04:46.000Z","comments":true,"path":"2017/04/15/20170415/","link":"","permalink":"https://wangkai1994.github.io/2017/04/15/20170415/","excerpt":"前后端分离的实践比较少，在写完接口，给前端时，前端说不能用，会有跨域问题，给我科普了 CORS，so 干错把跨域问题和解决的最佳实践了解清楚。 为什么会出现跨域及判定跨域，指的是浏览器不能执行其他网站的脚本。它是由浏览器的同源（域名，协议，端口）策略造成的，是浏览器对JavaScript施加的安全限制。 当前端调用处于不同域名或者端口的时候，就会出现跨域问题。","text":"前后端分离的实践比较少，在写完接口，给前端时，前端说不能用，会有跨域问题，给我科普了 CORS，so 干错把跨域问题和解决的最佳实践了解清楚。 为什么会出现跨域及判定跨域，指的是浏览器不能执行其他网站的脚本。它是由浏览器的同源（域名，协议，端口）策略造成的，是浏览器对JavaScript施加的安全限制。 当前端调用处于不同域名或者端口的时候，就会出现跨域问题。那么跨域问题是如何判定的呢？通过搜索和实验后得出以下步骤： 浏览器先根据同源策略对前端页面和后台交互地址做匹配，若同源，则直接发送数据请求；若不同源，则发送跨域请求。 服务器解析程序收到浏览器跨域请求后，根据自身配置返回对应文件头。若未配置过任何允许跨域，则文件头里不包含Access-Control-Allow-origin字段，若配置过域名，则返回Access-Control-Allow-origin+ 对应配置规则里的域名的方式。 浏览器根据接受到的http文件头里的Access-Control-Allow-origin字段做匹配，若无该字段，说明不允许跨域；若有该字段，则对字段内容和当前域名做比对，如果同源，则说明可以跨域，浏览器发送该请求；若不同源，则说明该域名不可跨域，不发送请求 解决跨域的最佳实践解决跨域的一般方法有 jsonp，CORS(修改 header 头)，端口转发等，前两者需要重写服务器代码，session 也会丢失。 有一种完美的解决方式就是端口转发。如果用前两者的方法，就必有多暴露出来的一个端口或者服务器 ip，如果只能使用一台服务器的一个端口进行部署时，jsonp 和 cors 就会失效。 如下图的配置文件所示，其前端页面配置在8080端口，后端服务器配置在8000端口，Nginx将前端对以http://localhost:8080/api/为前缀的请求转发到http://localhost:8000 12345678910111213server &#123; listen 8080; charset utf-8; location / &#123; root /home/ivan/Desktop/ProjectManagement/fontEnd; &#125; location ~ ^/api/&#123; proxy_pass http://localhost:8000; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For$proxy_add_x_forwarded_for; &#125;&#125; so，目前来看，nginx 还是部署前后端分离服务器时的最佳时间。开发环境中前端可以使用http-proxy-middleware的方式来解决跨域问题。","categories":[],"tags":[]},{"title":"python 项目部署步骤","slug":"20170315","date":"2017-03-15T09:55:28.000Z","updated":"2017-03-15T09:58:34.000Z","comments":true,"path":"2017/03/15/20170315/","link":"","permalink":"https://wangkai1994.github.io/2017/03/15/20170315/","excerpt":"","text":"1.安装 pyenv和 python 1234567891011121314$ curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bashexport PYENV_ROOT=&quot;$HOME/.pyenv&quot; -&gt;~/.bashrcexport PATH=&quot;$PYENV_ROOT/bin:$PATH&quot; -&gt;~/.bashrceval &quot;$(pyenv init -)&quot; -&gt;~/.bashrc$ sudo apt-get install libc6-dev gcc$ sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev$ pyenv install PYTHON_VERSION$ pyenv rehash$ cd PATH_TO_PROJECT$ pyenv local PYTHON_VERSION 2.安装mysql 123$ sudo apt-get install mysql-server$ sudo apt-get install libmysqlclient-devmysql&gt; CREATE DATABASE databasename_in_django_settings 3.pip install 12$ cd path/to/project $ pip instll-r path/to/requirements.txt 4.run project 123$ python manage.py makemigrations$ python manage.py migrate$ python manage.py runserver","categories":[],"tags":[]},{"title":"什么是第一范式，第二范式，第三范式？","slug":"20170308","date":"2017-03-08T15:28:23.000Z","updated":"2017-03-08T15:28:59.000Z","comments":true,"path":"2017/03/08/20170308/","link":"","permalink":"https://wangkai1994.github.io/2017/03/08/20170308/","excerpt":"","text":"什么是第一范式，第二范式，第三范式？翻译理解 stackoverflow 上的回答 第一范式：第一范式是所有普通表的基础，任何cell(单元，原子）在表中必须只包含一条信息，不能重复。 第二，第三范式都是依赖主键的。 第二范式： CourseID SemesterID #Places Course Name IT101 2009-1 100 Programming IT101 2009-2 100 Programming IT102 2009-1 200 Databases IT102 2010-1 150 Databases IT103 2009-2 120 Web Design 例子里的图就不是第二范式，因为CourseName 可以通过 CourseID来获取，所以表中的 CourseName 是重复的。不要冗余 第三范式： Course Semester #Places TeacherID TeacherName IT101 2009-1 100 332 Mr Jones IT101 2009-2 100 332 Mr Jones IT102 2009-1 200 495 Mr Bentley IT102 2010-1 150 332 Mr Jones IT103 2009-2 120 242 Mrs Smith 在Course的表里又有了 TeacherID,显而易见 TeacherName是冗余的，去掉。如果一个表只剩下了 Key，那就是第三范式。 The data depends on the key [1NF], the whole key [2NF] and nothing but the key [3NF]. 由第二范式可以引申出昨天那个变量和值的问题，第二范式希望数据是一个值而不是变量，你不是修改而是把他指向另外一个值。","categories":[],"tags":[]},{"title":"effective java 读书笔记(1)","slug":"20170307","date":"2017-03-07T14:42:32.000Z","updated":"2017-03-08T02:08:27.000Z","comments":true,"path":"2017/03/07/20170307/","link":"","permalink":"https://wangkai1994.github.io/2017/03/07/20170307/","excerpt":"effective java 读书笔记 金镝哥今天给我们做了第一次的培训和读书的分享，故结合自己的理解作一些读书笔记。 引伸开来的内容：前端发展对开发、设计等的启示（容易实践、普及&gt;&gt;设计精良）， python map/reduce等高阶函数的使用，对一个集合进行操作(list comprehension)。java的缺点，不灵活，缺少佚名函数，到8才支持 Lambda表达式。看看clojure，重构 编程珠玑。变量离使用的语句尽量近，多用表达式少用语句等编程技巧。 optional 在 java8中的使用可以看看 介绍了下 Joshua Bloch:google java 首席架构师 第一章 创建和修改对象：","text":"effective java 读书笔记 金镝哥今天给我们做了第一次的培训和读书的分享，故结合自己的理解作一些读书笔记。 引伸开来的内容：前端发展对开发、设计等的启示（容易实践、普及&gt;&gt;设计精良）， python map/reduce等高阶函数的使用，对一个集合进行操作(list comprehension)。java的缺点，不灵活，缺少佚名函数，到8才支持 Lambda表达式。看看clojure，重构 编程珠玑。变量离使用的语句尽量近，多用表达式少用语句等编程技巧。 optional 在 java8中的使用可以看看 介绍了下 Joshua Bloch:google java 首席架构师 第一章 创建和修改对象：1.考虑用静态工厂方法代替构造器 静态工厂方法有名字，取名字有考究。可以根据需要缓存，不用每一次都去 New 一个新的，或者可以根据需要去返回不一样的实现。 2.遇到多个构造器时要考虑用构造器 Builder 设计模式，属于 java 语言缺陷才特有的，可以对比参考 Python 的 **kwargs 传一个字典进去，return 的值也可以多返回值，自动解包。思考一门容易使用的语言需要什么特性 3.用私有构造器或者枚举类型强化 Singleton 属性 没什么好说的，推荐使用枚举 避免多次同步，没有并发问题。1234public enum Elvis&#123; INSTANCE; public void leaveTheBuilding()&#123;&#125; &#125; 4.通过私有构造器强化不可实例化的能力12345public class UtilityClass&#123; private UtilityClass()&#123; throw new Error(); &#125;&#125; 类似工具类会用这个，因为都是静态的不需要也不希望被实例化。自己写工具类是不必要的。java 8可以在 interface 里面写方法（默认方法）来实现。 5.避免创建不必要的对象 value 和 Variable的区别。类似==和 equals 区别的方式。不可变的就是 value，==就可以。尽量有原生的不要用包装类。把类设计成不可变的(String)，完美解决并发问题。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://wangkai1994.github.io/tags/读书笔记/"}]},{"title":"漫长的白日梦-浙大万朋工作总结与新的开始","slug":"20170305","date":"2017-03-05T12:59:59.000Z","updated":"2017-03-05T15:01:50.000Z","comments":true,"path":"2017/03/05/20170305/","link":"","permalink":"https://wangkai1994.github.io/2017/03/05/20170305/","excerpt":"","text":"当每一次面试，在等电梯的时候，我总是会想，如果能进这个公司就如何如何了，但是现实一般都是每个公司都不会太轻松或者太糟糕。非常兴奋的是宁波居然也能找到除了专业外包以外的公司，那么就来回顾一下浙大万朋的经历和展望下未来~ 结束金华工作的时候我喜欢把自己比作一个流水线工人，可以按照原来的功能依葫芦画瓢写一些新的功能，自知提升空间不是很足，而且内心很讨厌固定的 GUI 控件的写法，便联系了浙大万朋的赵老师。还不错，经过的一次明显双方都准备不足的面试以后（甚至一直还让我说还了解过什么），顺利的入职了实习生的岗位。我还是比较兴奋的，至少可以做一些真正有人用的东西。入职以后是需要完成一个 demo,类似 struts 的框架实践起来还是比较块的，但是学到了最重要的一个东西，就是需要考虑到可用性。比如任何的用户输入在前端js 和服务器端都需要做验证。还有就是需要考虑 IO 性能，不能把 dao 查询语句放进 for 循环里，尽量一起查出来放在 map 里，等等。工作期间，学习了 js，sql，java 的基础，集合的使用，框架的原理和作用，持续集成的使用，打包的方法等。工作的流程也规范了许多，有产品经理发任务单给我们，然后进行分工，使用 svn 来进行 commit 和 update 等，等前端给出页面 套模板，开发，开发完后提交给测试部门进行黑盒测试，RC 环境的测试，正式环境的测试，熬夜发布新的网站等。总体上来说，自己通过 java 网站的开发对一个网站怎么工作的有了一定的理解，上手别的框架的速度也快了许多。 新的公司主要的产品是一个监控数据库的系统，金镝哥还是一个很 nice 的人，希望可以学到更多互联网公司在使用的一些新技术，从多纬度的去学习解决问题的方式。 新的展望：近期的目标是学习 python,跟上新公司的节奏，熟悉 python 和 django 以后还是需要捡起来 java，锻炼自己快速解决问题的能力。长期的目标是找到适合自己发展的道路，在以后的5-10年有一个大概的规划。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://wangkai1994.github.io/tags/随笔/"}]},{"title":"2016 学了啥","slug":"2017","date":"2017-01-27T18:00:20.000Z","updated":"2017-01-27T18:49:44.000Z","comments":true,"path":"2017/01/28/2017/","link":"","permalink":"https://wangkai1994.github.io/2017/01/28/2017/","excerpt":"除夕的晚上，惯例还是写一些总结，但是今年想写的是关于技术的，以后可以公历写人的总结，除夕写技术的总结，或者交换下顺序。","text":"除夕的晚上，惯例还是写一些总结，但是今年想写的是关于技术的，以后可以公历写人的总结，除夕写技术的总结，或者交换下顺序。算是技术的汇报吧。 2016.7月之前，我还是呆在金华的公司，我想在这儿画个界限。 我是2015年11月入的职，所以1月到7月算是技术的高速成长期，我可以知道一个功能应该去怎么实现，怎么设计，需要注意什么。 知道了 dao dto 和 MVC 之类的原来很书本的知识存在的意义。 也大概的对 Spring 是一个什么东西有了大致的一个概念。 简单的来说，就是算是学会了编程去解决需求，但是做出来的只是玩具，现在看来有点漏洞百出的感觉。 熟练上手了 JSF 的使用方式和那一套 GUI 的方式;了解的事务的作用;了解到了数据库的连表查询; 通过修改模板学习到了一些 CSS+HTML 的使用方法;也开始对前端和后端有了一些最最基础的概念，入门看了 Scala,入门看了 node(es6),感觉node 的坑实在太大，应该是作为前端工作者的技能树，故舍弃。 找杭州的工作前，好好复习了 Java 的基础知识，背会了很多也在后面证明很有用的东西。 7.1号以后就入职了现在的公司。 学到的最深刻的就是 一个给人用的网站需要的可靠性稳定性（比如输入数据必须进行前端和后端的验证），其次是基本的技术 sql+js,这两项是再前一个公司完完全全没有接触的东西，会写，但是不熟练。 现在可以说是 sql和 js 的熟练工，知道用哪些 api 啊用法啊，但是还不知道原理(why)。 学会了 Struts 的用法；比较了 JSF 和 Struts 的用法区别； 看了一本 JVM 的书，科普到了 JVM 底层是有一些怎么样的东西； 看了 Spring in action 了解了 Spring 的配置的方法和可以胜任的工作，注解等; 又刷了一边数据结构和算法，这个应该还是会继续，有种常看常新的感觉，但是刷题的话真的感觉下班了以后脑子是僵硬的; 还在补 unp; Java web 也算补充了一点疏漏; github/git 的使用; Java 的一些基础的原理的理解; js 的深入学习，包括语法等，jquery 的各种 aqi 的熟练操作; maven 的操作,svn 的操作; 更深入的理解 mvc 的存在，Spring 的存在的意义; Spring mvc 熟练操作; 最近迫切的事情:补习 Java的面试技巧，看完 Spring in action ,补上 unp(写一个并发的服务器程序),efficient java，代码大全等可以补上。 2017希望继续让自己在2018总结时可以 wow 一下~","categories":[],"tags":[{"name":"总结","slug":"总结","permalink":"https://wangkai1994.github.io/tags/总结/"}]},{"title":"云趣的电话面试","slug":"20161211","date":"2016-12-11T07:54:44.000Z","updated":"2017-02-15T14:43:09.000Z","comments":true,"path":"2016/12/11/20161211/","link":"","permalink":"https://wangkai1994.github.io/2016/12/11/20161211/","excerpt":"","text":"equals hashcode 的区别（用法） jvm内存回收方法哪几种，类加载器有哪几个 final用法 stringBuilder stringBuffer List和Set的区别 底层实现 设计模式 单例模式 工厂模式 说说Spring的原理，作用域，AOP除了的before after还有什么 SpringMVC注解类型哪几种 核心方法 @requestBody Struts的实现原理相关 说说js闭包 多线程，同步，内存回收","categories":[{"name":"面试","slug":"面试","permalink":"https://wangkai1994.github.io/categories/面试/"}],"tags":[]},{"title":"LinkedList","slug":"LinkedList","date":"2016-09-28T14:38:44.000Z","updated":"2016-12-11T07:52:36.000Z","comments":true,"path":"2016/09/28/LinkedList/","link":"","permalink":"https://wangkai1994.github.io/2016/09/28/LinkedList/","excerpt":"LinkedListLinkedList &lt;–AbstractSequentialList &lt;–AbstractList&lt;–List&lt;–CollectionLinkedList是基于双向循环链表（从源码中可以很容易看出）实现的，除了可以当作链表来操作外，它还可以当作栈，队列和双端队列来使用。","text":"LinkedListLinkedList &lt;–AbstractSequentialList &lt;–AbstractList&lt;–List&lt;–CollectionLinkedList是基于双向循环链表（从源码中可以很容易看出）实现的，除了可以当作链表来操作外，它还可以当作栈，队列和双端队列来使用。 1、从源码中很明显可以看出，LinkedList的实现是基于双向循环链表的，且头结点中不存放数据，如下图;2、注意两个不同的构造方法。无参构造方法直接建立一个仅包含head节点的空链表，包含Collection的构造方法，先调用无参构造方法建立一个空链表，然后将Collection中的数据加入到链表的尾部后面。3、在查找和删除某元素时，源码中都划分为该元素为null和不为null两种情况来处理，LinkedList中允许元素为null。5、注意源码中的Entry entry(int index)方法。该方法返回双向链表中指定位置处的节点，而链表中是没有下标索引的，要指定位置出的元素，就要遍历该链表，从源码的实现中，我们看到这里有一个加速动作。源码中先将index与长度size的一半比较，如果indexsize/2，就只从位置size往前遍历到位置index处。这样可以减少一部分不必要的遍历，从而提高一定的效率（实际上效率还是很低）。6、注意链表类对应的数据结构Entry。如下; // 双向链表的节点所对应的数据结构。// 包含3部分：上一节点，下一节点，当前节点值。123456789101112131415161718192021private static class Entry&lt;E&gt; &#123; // 当前节点所包含的值 E element; // 下一个节点 Entry&lt;E&gt; next; // 上一个节点 Entry&lt;E&gt; previous; /** * 链表节点的构造函数。 * 参数说明： * element —— 节点所包含的数据 * next —— 下一个节点 * previous —— 上一个节点 */ Entry(E element, Entry&lt;E&gt; next, Entry&lt;E&gt; previous) &#123; this.element = element; this.next = next; this.previous = previous; &#125; &#125;","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/tags/数据结构/"}]},{"title":"LinkedHashMap","slug":"LinkedHashMap","date":"2016-09-28T14:38:08.000Z","updated":"2016-12-11T07:52:22.000Z","comments":true,"path":"2016/09/28/LinkedHashMap/","link":"","permalink":"https://wangkai1994.github.io/2016/09/28/LinkedHashMap/","excerpt":"LinkedHashMap是HashMap的子类，与HashMap有着同样的存储结构，但它加入了一个双向链表的头结点，将所有put到LinkedHashmap的节点一一串成了一个双向循环链表，因此它保留了节点插入的顺序，可以使节点的输出顺序与输入顺序相同。 LinkedHashMap可以用来实现LRU算法（这会在下面的源码中进行分析）。 LinkedHashMap同样是非线程安全的，只在单线程环境下使用。","text":"LinkedHashMap是HashMap的子类，与HashMap有着同样的存储结构，但它加入了一个双向链表的头结点，将所有put到LinkedHashmap的节点一一串成了一个双向循环链表，因此它保留了节点插入的顺序，可以使节点的输出顺序与输入顺序相同。 LinkedHashMap可以用来实现LRU算法（这会在下面的源码中进行分析）。 LinkedHashMap同样是非线程安全的，只在单线程环境下使用。 关于LinkedHashMap的源码，给出以下几点比较重要的总结： 1、从源码中可以看出，LinkedHashMap中加入了一个head头结点，将所有插入到该LinkedHashMap中的Entry按照插入的先后顺序依次加入到以head为头结点的双向循环链表的尾部。实际上就是HashMap和LinkedList两个集合类的存储结构的结合。在LinkedHashMapMap中，所有put进来的Entry都保存在如第一个图所示的哈希表中，但它又额外定义了一个以head为头结点的空的双向循环链表，每次put进来Entry，除了将其保存到对哈希表中对应的位置上外，还要将其插入到双向循环链表的尾部。 2、LinkedHashMap由于继承自HashMap，因此它具有HashMap的所有特性，同样允许key和value为null。 3、注意源码中的accessOrder标志位，当它false时，表示双向链表中的元素按照Entry插入LinkedHashMap到中的先后顺序排序，即每次put到LinkedHashMap中的Entry都放在双向链表的尾部，这样遍历双向链表时，Entry的输出顺序便和插入的顺序一致，这也是默认的双向链表的存储顺序；当它为true时，表示双向链表中的元素按照访问的先后顺序排列，可以看到，虽然Entry插入链表的顺序依然是按照其put到LinkedHashMap中的顺序，但put和get方法均有调用recordAccess方法（put方法在key相同，覆盖原有的Entry的情况下调用recordAccess方法），该方法判断accessOrder是否为true，如果是，则将当前访问的Entry（put进来的Entry或get出来的Entry）移到双向链表的尾部（key不相同时，put新Entry时，会调用addEntry，它会调用creatEntry，该方法同样将新插入的元素放入到双向链表的尾部，既符合插入的先后顺序，又符合访问的先后顺序，因为这时该Entry也被访问了），否则，什么也不做。 4、注意构造方法，前四个构造方法都将accessOrder设为false，说明默认是按照插入顺序排序的，而第五个构造方法可以自定义传入的accessOrder的值，因此可以指定双向循环链表中元素的排序规则，一般要用LinkedHashMap实现LRU算法，就要用该构造方法，将accessOrder置为true。 5、LinkedHashMap并没有覆写HashMap中的put方法，而是覆写了put方法中调用的addEntry方法和recordAccess方法，我们回过头来再看下HashMap的put方法： // 将“key-value”添加到HashMap中 public V put(K key, V value) { // 若“key为null”，则将该键值对添加到table[0]中。 if (key == null) return putForNullKey(value); // 若“key不为null”，则计算该key的哈希值，然后将其添加到该哈希值对应的链表中。 int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; // 若“该key”对应的键值对已经存在，则用新的value取代旧的value。然后退出！ if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } // 若“该key”对应的键值对不存在，则将“key-value”添加到table中 modCount++; //将key-value添加到table[i]处 addEntry(hash, key, value, i); return null; } 当要put进来的Entry的key在哈希表中已经在存在时，会调用recordAccess方法，当该key不存在时，则会调用addEntry方法将新的Entry插入到对应槽的单链表的头部。 我们先来看recordAccess方法： //覆写HashMap中的addEntry方法，LinkedHashmap并没有覆写HashMap中的put方法， //而是覆写了put方法所调用的addEntry方法和recordAccess方法， //put方法在插入的key已存在的情况下，会调用recordAccess方法， //在插入的key不存在的情况下，要调用addEntry插入新的Entry void addEntry(int hash, K key, V value, int bucketIndex) { //创建新的Entry，并插入到LinkedHashMap中 createEntry(hash, key, value, bucketIndex); //双向链表的第一个有效节点（header后的那个节点）为近期最少使用的节点 Entry&lt;K,V&gt; eldest = header.after; //如果有必要，则删除掉该近期最少使用的节点， //这要看对removeEldestEntry的覆写,由于默认为false，因此默认是不做任何处理的。 if (removeEldestEntry(eldest)) { removeEntryForKey(eldest.key); } else { //扩容到原来的2倍 if (size &gt;= threshold) resize(2 * table.length); } } void createEntry(int hash, K key, V value, int bucketIndex) { //创建新的Entry，并将其插入到数组对应槽的单链表的头结点处，这点与HashMap中相同 HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(hash, key, value, old); table[bucketIndex] = e; //每次插入Entry时，都将其移到双向链表的尾部， //这便会按照Entry插入LinkedHashMap的先后顺序来迭代元素， //同时，新put进来的Entry是最近访问的Entry，把其放在链表末尾 ，符合LRU算法的实现 e.addBefore(header); size++; } 同样是将新的Entry插入到table中对应槽所对应单链表的头结点中，但可以看出，在createEntry中，同样把新put进来的Entry插入到了双向链表的尾部，从插入顺序的层面来说，新的Entry插入到双向链表的尾部，可以实现按照插入的先后顺序来迭代Entry，而从访问顺序的层面来说，新put进来的Entry又是最近访问的Entry，也应该将其放在双向链表的尾部。 上面还有个removeEldestEntry方法，该方法如下： //该方法是用来被覆写的，一般如果用LinkedHashmap实现LRU算法，就要覆写该方法， //比如可以将该方法覆写为如果设定的内存已满，则返回true，这样当再次向LinkedHashMap中put //Entry时，在调用的addEntry方法中便会将近期最少使用的节点删除掉（header后的那个节点）。 protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { return false; } } 该方法默认返回false，我们一般在用LinkedHashMap实现LRU算法时，要覆写该方法，一般的实现是，当设定的内存（这里指节点个数）达到最大值时，返回true，这样put新的Entry（该Entry的key在哈希表中没有已经存在）时，就会调用removeEntryForKey方法，将最近最少使用的节点删除（head后面的那个节点，实际上是最近没有使用）。 6、LinkedHashMap覆写了HashMap的get方法： //覆写HashMap中的get方法，通过getEntry方法获取Entry对象。 //注意这里的recordAccess方法， //如果链表中元素的排序规则是按照插入的先后顺序排序的话，该方法什么也不做， //如果链表中元素的排序规则是按照访问的先后顺序排序的话，则将e移到链表的末尾处。 public V get(Object key) { Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; e.recordAccess(this); return e.value; } 先取得Entry，如果不为null，一样调用recordAccess方法，上面已经说得很清楚，这里不在多解释了。 7、最后说说LinkedHashMap是如何实现LRU的。首先，当accessOrder为true时，才会开启按访问顺序排序的模式，才能用来实现LRU算法。我们可以看到，无论是put方法还是get方法，都会导致目标Entry成为最近访问的Entry，因此便把该Entry加入到了双向链表的末尾（get方法通过调用recordAccess方法来实现，put方法在覆盖已有key的情况下，也是通过调用recordAccess方法来实现，在插入新的Entry时，则是通过createEntry中的addBefore方法来实现），这样便把最近使用了的Entry放入到了双向链表的后面，多次操作后，双向链表前面的Entry便是最近没有使用的，这样当节点个数满的时候，删除的最前面的Entry(head后面的那个Entry)便是最近最少使用的Entry。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/tags/数据结构/"}]},{"title":"hashTable","slug":"hashTable","date":"2016-09-28T14:36:43.000Z","updated":"2016-09-28T14:37:38.000Z","comments":true,"path":"2016/09/28/hashTable/","link":"","permalink":"https://wangkai1994.github.io/2016/09/28/hashTable/","excerpt":"HashTable同样是基于哈希表实现的，同样每个元素都是key-value对，其内部也是通过单链表解决冲突问题，容量不足（超过了阈值）时，同样会自动增长。 Hashtable也是JDK1.0引入的类，是线程安全的，能用于多线程环境中。 Hashtable同样实现了Serializable接口，它支持序列化，实现了Cloneable接口，能被克隆。 针对Hashtable，我们同样给出几点比较重要的总结，但要结合与HashMap的比较来总结。 二者的存储结构和解决冲突的方法都是相同的。 HashTable在不指定容量的情况下的默认容量为11，而HashMap为16，Hashtable不要求底层数组的容量一定要为2的整数次幂，而HashMap则要求一定为2的整数次幂。 Hashtable中key和value都不允许为null，而HashMap中key和value都允许为null（key只能有一个为null，而value则可以有多个为null）。但是如果在Hashtable中有类似put(null,null)的操作，编译同样可以通过，因为key和value都是Object类型，但运行时会抛出NullPointerException异常，这是JDK的规范规定的。我们来看下ContainsKey方法和ContainsValue的源码：","text":"HashTable同样是基于哈希表实现的，同样每个元素都是key-value对，其内部也是通过单链表解决冲突问题，容量不足（超过了阈值）时，同样会自动增长。 Hashtable也是JDK1.0引入的类，是线程安全的，能用于多线程环境中。 Hashtable同样实现了Serializable接口，它支持序列化，实现了Cloneable接口，能被克隆。 针对Hashtable，我们同样给出几点比较重要的总结，但要结合与HashMap的比较来总结。 二者的存储结构和解决冲突的方法都是相同的。 HashTable在不指定容量的情况下的默认容量为11，而HashMap为16，Hashtable不要求底层数组的容量一定要为2的整数次幂，而HashMap则要求一定为2的整数次幂。 Hashtable中key和value都不允许为null，而HashMap中key和value都允许为null（key只能有一个为null，而value则可以有多个为null）。但是如果在Hashtable中有类似put(null,null)的操作，编译同样可以通过，因为key和value都是Object类型，但运行时会抛出NullPointerException异常，这是JDK的规范规定的。我们来看下ContainsKey方法和ContainsValue的源码： 1234567891011121314151617181920212223242526272829303132333435363738 // 判断Hashtable是否包含“值(value)” public synchronized boolean contains(Object value) &#123; //注意，Hashtable中的value不能是null， // 若是null的话，抛出异常! if (value == null) &#123; throw new NullPointerException(); &#125; // 从后向前遍历table数组中的元素(Entry) // 对于每个Entry(单向链表)，逐个遍历，判断节点的值是否等于value Entry tab[] = table; for (int i = tab.length ; i-- &gt; 0 ;) &#123; for (Entry&lt;K,V&gt; e = tab[i] ; e != null ; e = e.next) &#123; if (e.value.equals(value)) &#123; return true; &#125; &#125; &#125; return false; &#125;public boolean containsValue(Object value) &#123; return contains(value); &#125; // 判断Hashtable是否包含key public synchronized boolean containsKey(Object key) &#123; Entry tab[] = table; /计算hash值，直接用key的hashCode代替 int hash = key.hashCode(); // 计算在数组中的索引值 int index = (hash &amp; 0x7FFFFFFF) % tab.length; // 找到“key对应的Entry(链表)”，然后在链表中找出“哈希值”和“键值”与key都相等的元素 for (Entry&lt;K,V&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return true; &#125; &#125; return false; &#125; 很明显，如果value为null，会直接抛出NullPointerException异常，但源码中并没有对key是否为null判断，有点小不解！不过NullPointerException属于RuntimeException异常，是可以由JVM自动抛出的，也许对key的值在JVM中有所限制吧。 Hashtable扩容时，将容量变为原来的2倍加1，而HashMap扩容时，将容量变为原来的2倍。 Hashtable和HashMap都重新计算了key的hash值，Hashtable在求hash值对应的位置索引时，用取模运算，而HashMap在求位置索引时，则用与运算，且这里一般先用hash&amp;0x7FFFFFFF后，再对length取模，&amp;0x7FFFFFFF的目的是为了将负的hash值转化为正值，因为hash值有可能为负数，而&amp;0x7FFFFFFF后，只有符号外改变，而后面的位都不变。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/tags/数据结构/"}]},{"title":"hashMap","slug":"hashMap","date":"2016-09-28T14:35:29.000Z","updated":"2016-09-28T14:37:51.000Z","comments":true,"path":"2016/09/28/hashMap/","link":"","permalink":"https://wangkai1994.github.io/2016/09/28/hashMap/","excerpt":"Java集合类的图","text":"Java集合类的图 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123;//初始化//initialCapacity 容量大小 loadFactor 加载因子 public HashMap(int initialCapacity, float loadFactor) &#123; //先判断容量，不够就*2。初始值static final int DEFAULT_INITIAL_CAPACITY = 16; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // Find a power of 2 &gt;= initialCapacity int capacity = 1; //找出“大于initialCapacity”的最小的2的幂 while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; this.loadFactor = loadFactor; // 设置“HashMap阈值”，当HashMap中存储数据的数量达到threshold时，就需要将HashMap的容量加倍。 threshold = (int)Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 创建Entry数组，用来保存数据 table = new Entry[capacity]; useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); init(); final int hash(Object k) &#123; int h = 0; if (useAltHashing) &#123; if (k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h = hashSeed; &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key); //用hash来散列位置 其中用a&amp;(b-1)来代替a%b,效率更高 int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; // 获取key对应的value public V get(Object key) &#123; if (key == null) return getForNullKey(); // 获取key的hash值 int hash = hash(key.hashCode()); // 在“该hash值对应的链表”上查找“键值等于key”的元素 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; //判断key是否相同 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; &#125; //没找到则返回null return null; &#125; &#125;&#125; hashmap总结：1.存储结构紫色部分代表哈希表，链表用于解决冲突，如果不同的key映射到了数组的同一位置，就将放入单链表中。（hash值 取模了位置会相同！）2、首先看链表中节点的数据结构：它的结构元素除了key、value、hash外，还有next，next指向下一个节点。另外，这里覆写了equals和hashCode方法来保证键值对的独一无二。 3、HashMap共有四个构造方法。构造方法中提到了两个很重要的参数：初始容量和加载因子。这两个参数是影响HashMap性能的重要参数，其中容量表示哈希表中槽的数量（即哈希数组的长度），初始容量是创建哈希表时的容量（从构造函数中可以看出，如果不指明，则默认为16），加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 resize 操作（即扩容）。 下面说下加载因子，如果加载因子越大，对空间的利用更充分，但是查找效率会降低（链表长度会越来越长）；如果加载因子太小，那么表中的数据将过于稀疏（很多空间还没用，就开始扩容了），对空间造成严重浪费。如果我们在构造方法中不指定，则系统默认加载因子为0.75，这是一个比较理想的值，一般情况下我们是无需修改的。 另外，无论我们指定的容量为多少，构造方法都会将实际容量设为不小于指定容量的2的次方的一个数，且最大值不能超过2的30次方 4、HashMap中key和value都允许为null。 5、要重点分析下HashMap中用的最多的两个方法put和get。先从比较简单的get方法着手，源码如下：12345678910111213141516171819202122232425262728// 获取key对应的value public V get(Object key) &#123; if (key == null) return getForNullKey(); // 获取key的hash值 int hash = hash(key.hashCode()); // 在“该hash值对应的链表”上查找“键值等于key”的元素 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; /判断key是否相同 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; &#125; 没找到则返回null return null; &#125; // 获取“key为null”的元素的值 // HashMap将“key为null”的元素存储在table[0]位置，但不一定是该链表的第一个位置！ private V getForNullKey() &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) return e.value; &#125; return null; &#125; 首先，如果key为null，则直接从哈希表的第一个位置table[0]对应的链表上查找。记住，key为null的键值对永远都放在以table[0]为头结点的链表中，当然不一定是存放在头结点table[0]中。 如果key不为null，则先求的key的hash值，根据hash值找到在table中的索引，在该索引对应的单链表中查找是否有键值对的key与目标key相等，有就返回对应的value，没有则返回null。 put方法稍微复杂些，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142 // 将“key-value”添加到HashMap中 public V put(K key, V value) &#123; // 若“key为null”，则将该键值对添加到table[0]中。 if (key == null) return putForNullKey(value); // 若“key不为null”，则计算该key的哈希值，然后将其添加到该哈希值对应的链表中。 int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 若“该key”对应的键值对已经存在，则用新的value取代旧的value。然后退出！ if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; // 若“该key”对应的键值对不存在，则将“key-value”添加到table中 modCount++; //将key-value添加到table[i]处 addEntry(hash, key, value, i); return null; &#125; 如果key为null，则将其添加到table[0]对应的链表中，putForNullKey的源码如下：// putForNullKey()的作用是将“key为null”键值对添加到table[0]位置 private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; // 如果没有存在key为null的键值对，则直接题阿见到table[0]处! modCount++; addEntry(0, null, value, 0); return null; &#125; 如果key不为null，则同样先求出key的hash值，根据hash值得出在table中的索引，而后遍历对应的单链表，如果单链表中存在与目标key相等的键值对，则将新的value覆盖旧的value，比将旧的value返回，如果找不到与目标key相等的键值对，或者该单链表为空，则将该键值对插入到改单链表的头结点位置（每次新插入的节点都是放在头结点的位置），该操作是有addEntry方法实现的，它的源码如下：1234567891011// 新增Entry。将“key-value”插入指定位置，bucketIndex是位置索引。 void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 保存“bucketIndex”位置的值到“e”中 Entry&lt;K,V&gt; e = table[bucketIndex]; // 设置“bucketIndex”位置的元素为“新Entry”， // 设置“e”为“新Entry的下一个节点” table[bucketIndex] = new Entry&lt;K,V&gt;(hash, key, value, e); // 若HashMap的实际大小 不小于 “阈值”，则调整HashMap的大小 if (size++ &gt;= threshold) resize(2 * table.length); &#125; 注意这里倒数第三行的构造方法，将key-value键值对赋给table[bucketIndex]，并将其next指向元素e，这便将key-value放到了头结点中，并将之前的头结点接在了它的后面。该方法也说明，每次put键值对的时候，总是将新的该键值对放在table[bucketIndex]处（即头结点处）。 两外注意最后两行代码，每次加入键值对时，都要判断当前已用的槽的数目是否大于等于阀值（容量*加载因子），如果大于等于，则进行扩容，将容量扩为原来容量的2倍。 6、关于扩容。上面我们看到了扩容的方法，resize方法，它的源码如下：12345678910111213141516// 重新调整HashMap的大小，newCapacity是调整后的单位 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 新建一个HashMap，将“旧HashMap”的全部元素添加到“新HashMap”中， // 然后，将“新HashMap”赋值给“旧HashMap”。 Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor); &#125; 很明显，是新建了一个HashMap的底层数组，而后调用transfer方法，将就HashMap的全部元素添加到新的HashMap中（要重新计算元素在新的数组中的索引位置）。transfer方法的源码如下：123456789101112131415161718// 将HashMap中的全部元素都添加到newTable中 void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125; &#125; 很明显，扩容是一个相当耗时的操作，因为它需要重新计算这些元素在新的数组中的位置并进行复制处理。因此，我们在用HashMap的时，最好能提前预估下HashMap中元素的个数，这样有助于提高HashMap的性能。 7、注意containsKey方法和containsValue方法。前者直接可以通过key的哈希值将搜索范围定位到指定索引对应的链表，而后者要对哈希数组的每个链表进行搜索。 8、我们重点来分析下求hash值和索引值的方法，这两个方法便是HashMap设计的最为核心的部分，二者结合能保证哈希表中的元素尽可能均匀地散列。 计算哈希值的方法如下：1234static int hash(int h) &#123; h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 它只是一个数学公式，IDK这样设计对hash值的计算，自然有它的好处，至于为什么这样设计，我们这里不去追究，只要明白一点，用的位的操作使hash值的计算效率很高。 由hash值找到对应索引的方法如下：123static int indexFor(int h, int length) &#123; return h &amp; (length-1); &#125; 这个我们要重点说下，我们一般对哈希表的散列很自然地会想到用hash值对length取模（即除法散列法），Hashtable中也是这样实现的，这种方法基本能保证元素在哈希表中散列的比较均匀，但取模会用到除法运算，效率很低，HashMap中则通过h&amp;(length-1)的方法来代替取模，同样实现了均匀的散列，但效率要高很多，这也是HashMap对Hashtable的一个改进。 接下来，我们分析下为什么哈希表的容量一定要是2的整数次幂。首先，length为2的整数次幂的话，h&amp;(length-1)就相当于对length取模，这样便保证了散列的均匀，同时也提升了效率；其次，length为2的整数次幂的话，为偶数，这样length-1为奇数，奇数的最后一位是1，这样便保证了h&amp;(length-1)的最后一位可能为0，也可能为1（这取决于h的值），即与后的结果可能为偶数，也可能为奇数，这样便可以保证散列的均匀性，而如果length为奇数的话，很明显length-1为偶数，它的最后一位是0，这样h&amp;(length-1)的最后一位肯定为0，即只能为偶数，这样任何hash值都只会被散列到数组的偶数下标位置上，这便浪费了近一半的空间，因此，length取2的整数次幂，是为了使不同hash值发生碰撞的概率较小，这样就能使元素在哈希表中均匀地散列。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/tags/数据结构/"}]},{"title":"挖财一面","slug":"20160904","date":"2016-09-23T15:05:40.000Z","updated":"2016-09-12T15:05:54.000Z","comments":true,"path":"2016/09/23/20160904/","link":"","permalink":"https://wangkai1994.github.io/2016/09/23/20160904/","excerpt":"","text":"自我介绍 公司经历 业务了解 数据结构 链表/数组 算法 排序/查找 时间复杂度空间复杂度 网络 三次握手 和 四次挥手 dns是什么 Java中的集合 hashmap hash算法 Spring的AOP和控制反转 没有认真准备，一面被刷，以上","categories":[{"name":"面试","slug":"面试","permalink":"https://wangkai1994.github.io/categories/面试/"}],"tags":[]},{"title":"resume","slug":"resume","date":"2016-03-08T03:50:59.000Z","updated":"2016-03-11T12:44:26.000Z","comments":true,"path":"2016/03/08/resume/","link":"","permalink":"https://wangkai1994.github.io/2016/03/08/resume/","excerpt":"","text":"联系方式 手机：18395920740 Email：wangkaizjnu@foxmail.com QQ/微信号：494931023 个人信息 王开/男/1994 本科(2017届大三)/浙江师范大学行知学院计算机科学与技术专业 技术博客：http://kai660740.github.io Github：https://github.com/kai660740 期望职位：Java研发实习生 期望城市：杭州 #学习路线 ##JavaJava SE-&gt;servlet-&gt;jsp-&gt;jdbc-&gt;数据库小项目-&gt;MVC框架（Spring,mybatis,Hibernate）-&gt;研究过nio的使用-&gt;在项目中回顾Java的基础 ##其他技术 TCP/IP、设计模式、浅层次的Python和Scala+Spark、数据库(Mysql/Redis)基础、玩过Android开发+Swift2.0、OS X、爬虫 ##计划学习 Unix下Shell编程、数据库更加深入的了解，体会nosql（MongoDB、radis）的优点、深入学习Scala、写一个简单的框架(类似jfinal)或者稳定的中间件 工作经历浙江立盛网络科技公司 （ 2015年11月 ~ 至今 ）工程OA开发 短时间内熟悉JSF+Spring框架 熟悉代码规范 学习如何Debug 接触到串口开发，阅读英文文档速度提升 第一次大项目经历、了解Svn的使用 某商店客户系统 学习处理复杂的业务逻辑 了解框架的运行原理 代码持久性的重要 其他项目独立完成了公司产品主页的开发(www.dq56lm.com)解决了各个浏览器的兼容性问题。 作品 工程管理系统 客户系统 大作业：基于Dijkstra算法的校园导航、使用JDBC、JSP的数据库大作业、 为了炒股写ajxs查看实时股票价格(暂时没上传，稍后会整理放到个人博客) 斗鱼弹幕爬虫 阅读过的书籍和开源代码##书籍 算法竞赛入门经典 刘汝佳著(竞赛部分没看) Computer Networks A Top-Down Approach Behrouz A.Forouzan 深入分析Java Web内幕 许令波 大话设计模式 程杰 疯狂Java讲义 李刚(没有完整看，当字典查) Spring 源码深度解析(100页左右) JavaServer Faces核心编程 MySQL Cookbook(翻了一边) Thinking in Java (当字典查) ##开源项目与新技术 了解并使用过jfinal 关注Scala和Spark、函数式编程语言 了解、实现Docker，nginx的部署和配置 阅读过TeamTalk部分 使用过swift2.0(写Iphone计算器) #技能清单 开发语言: Java/Python(初学) Web框架: Struts2/Spring/JSF 数据库相关: Mysql 版本管理、文档和自动化工具：Svn/Markdown 操作系统：OS X 常年使用 编辑器、IDE：Sublime/Eclipse/MyEclipse 致谢感谢您花时间阅读我的简历，期待能有机会和您共事。","categories":[],"tags":[{"name":"简历","slug":"简历","permalink":"https://wangkai1994.github.io/tags/简历/"}]},{"title":"shixi1","slug":"shixi1","date":"2015-12-07T15:13:53.000Z","updated":"2015-12-07T15:52:46.000Z","comments":true,"path":"2015/12/07/shixi1/","link":"","permalink":"https://wangkai1994.github.io/2015/12/07/shixi1/","excerpt":"","text":"###大三的实习&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;很久没更新博客，言归正传，在大二下和寒假再加上大三的前2个月，我勉强看完了java web的基础部分、网页的设计、数据库的基础、SSH框架也看了sturts2和Hibernate 两部分。跟着网上的写了一个小的内存管理系统Dome就觉得差不多了，我觉得没什么必要“深入”，现在看来还是太年轻。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着我就有点按耐不住自己的性子，想要突破一下自己了，看到了学长们纷纷在杭州等找到了实习，我也蠢蠢欲动，翻出了很早以前的想法就开始找金华的实习，没办法实在太空了，一周就3天早上有课，完全有时间去实习。看到了一家公司叫”立盛”我就投了，心里想着有公司就蛮不错了。面试的过程和我想象的完全不一样，就是简单的聊了一下，把我做的dome给老板看一下，老板估计正好缺人，就说来把，2000一月。ok，上班开始了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一天就是一个坑，老板坚持用他们的电脑，要知道我已经很久没有用windows的系统，再加上是myeclipse,很不习惯，想调用Maven配一个环境，没想到各种错误始料未及的那种。开始就让我熟悉一个jsf的框架，很古老的框架，可以算是一个去掉事务层的 标签库 。 网页用的是xhtml，什么鬼现在还不懂，能用就好。我第一天找了一本Jsf的书，一个上午看了50-60页总算搞懂了一些基本用法，写了一个hello world还是各种错误，很不能忍，傻逼电脑，每过2分钟我就想换我的mac用算了。但是还是坚持下来了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;老板的第一个任务就是随便写一个东西给他看，ok，搞了半天，用了Myfaces，写了一个可以和hibernate连起来的login界面。好像已经是礼拜4了。我礼拜1上的班。我自己觉得还是有点慢的，但是jsf的坑还是很多，再加上适应电脑，我也就满满接受了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后来就搬到了楼上，一个更大的办公室，老板接着给了我一个gcoa的东西，车辆管理系统，让我改一个原料管理系统这个很坑。我开始学着看他们的代码，结合了spring 我完全看不懂，大概结合着网页整整看了1天把，第二天终于知道了一些，分层，注解，spring的用法，开始模仿的写功能，第三天，第四天，发现写的功能老板以前都写过，放在另外一个包里，就用他的改，和老板确定功能。第五天第六天逐渐把功能的界面也写出来了，和数据库也联通了，dto ,dao,dxo，也懂了一些意图。马上，傻傻的写了一些曾删改差的功能，自我感觉还可以。大概是第三周了。接下来的日子就是开始为公司的一个项目写一个静态的网站，下了一个模板，改了一些CSS，文字，以前完全没做过这些。感觉还成把，第一次写，老板要求也不高，应该是可以了。接下来就是在调试我的短信猫，应该快3天了，终于了解短星猫。。。现在看来学到是有点慢?&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来的计划，下班时间6-7点这样，仔细学spring，基本完成那个功能的编写。看一些spring的源码，有空看Jvm。下班以后去健健身，游戏还是周567打打就好了，期末也快了，需要收收心，关注下操作系统的内容。寝室里学不进就只能在公司多带一会喽。听说老板有个分销系统让我写，压力好大。好像还有个蓝桥杯，明天报个名好了！别忘记了！加油。","categories":[],"tags":[{"name":"实习","slug":"实习","permalink":"https://wangkai1994.github.io/tags/实习/"}]},{"title":"数据库项目个人总结","slug":"购物系统总结","date":"2015-06-15T09:50:38.000Z","updated":"2015-06-15T09:54:45.000Z","comments":true,"path":"2015/06/15/购物系统总结/","link":"","permalink":"https://wangkai1994.github.io/2015/06/15/购物系统总结/","excerpt":"##1.项目目标","text":"##1.项目目标&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立一个具有基本功能的购物网站，需要完成的功能是，有一个登录界面，需要帐号密码与后台匹配才能进入。进入以后到达一个商品选择的页面，出现的是数据库goods中的各个商品的名称，简介，价格，是否加入购物车。点击加入购物车后跳转到购物车界面，可以选择继续购买和付钱选项。 ##2.解决思路&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一开始的解决思路是html+servlet的解决思路，但是发现简单的servlet不能解决最简单的排版等工作，代码会很麻烦。继续学习以后，发现jsp很符合我的需求，于是就留了一个html来进行登录操作，后面涉及数据库读取等内容使用jsp完成。 ##3.遇到问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一开始我设计的是点击html标签中的Button按钮来进行跳转到购物车页面的操作，但是实际编写时发现，按钮很难去传输选定的那一个商品。后来通过学习，发现通过超级链接可以完美解决。 ##4.项目总结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个项目的意义在于对自己初学sql和Java Web内容的一个总结复习。这个项目顺利的使我把学到的知识用到了项目中。后续还可以在这个项目的基础上加上其他功能。","categories":[{"name":"-数据库","slug":"数据库","permalink":"https://wangkai1994.github.io/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://wangkai1994.github.io/tags/数据库/"}]},{"title":"MySQL学习笔记","slug":"learnmysql","date":"2015-05-09T06:07:01.000Z","updated":"2015-06-15T09:53:33.000Z","comments":true,"path":"2015/05/09/learnmysql/","link":"","permalink":"https://wangkai1994.github.io/2015/05/09/learnmysql/","excerpt":"###mysql笔记","text":"###mysql笔记 show database //查看当前存在的数据库 create database test //创建新的数据库 use test //选择数据库 show tables //查看表 drop database test //删除 create table class(stu int, name varchar(20),age int,area varchar(20)); //创建表 rename table class to newclass //重命名 drop table newclass //删表 desc class //描述表 insert into msg (id,title,name,content )values (1,’aa’,’aa’,’sss’); //插入一列值 updata msg set id =2, content = ‘ a’ where name =’l’ //修改值 insert into msf (id,title,name,content) values (3,’3’,’aa’,’aa’) , (4,’4’,’aaa’,’a’) //插入多行 delete from msg where name =.. //删除一行 select * from msg; //查一个表 select * from msg where id &gt;2 ; // select id title from msg where id&gt;2;//条件查找","categories":[{"name":"-数据库","slug":"数据库","permalink":"https://wangkai1994.github.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://wangkai1994.github.io/tags/mysql/"}]},{"title":"大二下学期计划","slug":"termPlan1","date":"2015-03-10T16:16:51.000Z","updated":"2015-03-10T16:17:52.000Z","comments":true,"path":"2015/03/11/termPlan1/","link":"","permalink":"https://wangkai1994.github.io/2015/03/11/termPlan1/","excerpt":"","text":"#####1.计算机科学 学好 数据库 sql ——》熟练操作，搞懂原理。 学好 计算机网络，tcp/ip协议，——》对于网络有更加深层次的理解，在编程中熟练应用。 学通 微机与汇编语言——》毕业前完成一个简单的编译器。 继续 leetcode 数据结构 算法 –&gt;完成30题 #####2.计算机技术 完成对于java web的学习 ——》开发一套动态网页 辅助android 学习-》开发简单的app","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://wangkai1994.github.io/tags/随笔/"}]},{"title":"大二上短学期作业总结：校园导航","slug":"project-review1","date":"2015-03-10T15:57:20.000Z","updated":"2015-03-10T16:00:34.000Z","comments":true,"path":"2015/03/10/project-review1/","link":"","permalink":"https://wangkai1994.github.io/2015/03/10/project-review1/","excerpt":"####1.问题描述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设计一个校园导航程序，为来访的客人提供住处查询服务。选取苦干（多于10个）个有代表性的景点抽象成一个无向带权图，以图中顶点表示校内景点，边上的权值表示两景点间的距离。","text":"####1.问题描述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设计一个校园导航程序，为来访的客人提供住处查询服务。选取苦干（多于10个）个有代表性的景点抽象成一个无向带权图，以图中顶点表示校内景点，边上的权值表示两景点间的距离。 ####2. 具体功能要求1） 学校景点介绍：由一个子函数实现，输出学校全部景点的信息，包括景点编号、名称及简介。2） 查看浏览路线：根据用户输入的起始景点编号，求出从该景点到其他景点的最短路径线路及距离，要求用DIJKSTRA算法完成。3） 查询景点间最短路径：两个景点间的最短路径，要求用FLOYD算法完成。4） 景点信息查询：根据用户输入的编号，输出其相关信息。5） 更改基本信息：新增景点，删除边，重建图等。6） 查询景点间可行路径：显示所有符合长度限制（如路径长度不大于5）的所有路径。（可选做）7） 打印图8） 退出 ####3.概要设计 ######3.1“系统框架图” 注：因为第一次接触一个软件的开发，没学过软件工程，对于框图的理解几乎为零，这个框图仅仅是为了便于理解整个软件的框架。 #####3.2 开发思路，困难与解决&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先是平台选择，老师布置完作业以后，我在脑子里大概构思出了一个软件的框架。老师推荐的是C语言或者C++。我作为我们组的主要开发者，觉得不如用用刚学完的java语言，虽然swing在现在不常用，但是对于我们的任务来说还是绰绰有余。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一天晚上就开始着手先试试java swing界面的建立，主要当时短学期未开始，为了不坑队友，我便先试试水。一开始很傻，没有用可视化界面去建立swing，我来我想着不对劲，就是网上下载了swing builder。发现简直是神器，不用再手动setbounds 不一会，我们软件的雏形已经出现了。但是当时我遇到了一个问题，如何点击一个按钮，让对应功能的“界面”出现呢。这个问题困扰了我2小时左右，我不断的google 百度，但是我找不到合适的词去描述这个问题，但是在google寻找的过程中，我突然发现有个功能是setVisiable 不知道是不是我要的那个，于是我便去试了，把两个界面的大小位置完全设置成一样，点击按钮的时候当前界面不可见，所指界面可见，问题解决！！后面反着找了一些，swing里面好像就是用这个解决的，大喜。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;界面的问题解决以后，我的心事就放下一半了，至少不会坑队友了。那接下来考虑的是什么呢？算法。这两题的核心其实就是算法。我的水平有些菜，上完数据结构以后对于Dijkstra算法的理解仅仅在理论不能去裸写一个出来，网上百度一个靠谱的，复制粘贴，随意的设置了一个邻接表，可行。但是这个时候我发现，TMD邻接矩阵怎么办，图怎么存？存的问题，我一开始想的是存在一个二维数组里面就好了，需要的时候改就行了。但是，java是面向对象的语言，我每次点击按钮的时候就是new 一个新的对象出来，修改也只是在New出来的对象上面，不能永久保存。这个问题让我失眠了一个晚上，在后面一天洗澡的时候，我突然想到我可以用一个txt文件去保存，到时候读文件就好了。经过百度google，基本确定了这个方案是可行的，读行的时候把空格读出来，剩下的自动建立一个二维数组，这个算法也挺烦的，搞了半个小时才完成，好在都能用，也算是节约了时间。","categories":[],"tags":[{"name":"大作业总结","slug":"大作业总结","permalink":"https://wangkai1994.github.io/tags/大作业总结/"}]},{"title":"数据结构笔记2","slug":"sjjg2","date":"2015-01-05T15:54:43.000Z","updated":"2015-01-05T15:57:26.000Z","comments":true,"path":"2015/01/05/sjjg2/","link":"","permalink":"https://wangkai1994.github.io/2015/01/05/sjjg2/","excerpt":"###数据结构（二）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出了一点小意外，发现看清华大学的那个视频进度太慢，估计看到春节才能看完吧？所以，果断转头到浙江大学的怀抱，视频还挺好的。下面是一些笔记把，不记下来估计就扔掉了。","text":"###数据结构（二）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出了一点小意外，发现看清华大学的那个视频进度太慢，估计看到春节才能看完吧？所以，果断转头到浙江大学的怀抱，视频还挺好的。下面是一些笔记把，不记下来估计就扔掉了。 ####1.二分查找 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;二分查找的前提是在一个有序的数列里面。总的思路是减而治之。具体说的话就是：先从中间开始比较，看是比中间的数字小还是大，对应的就是左边查找还是右边查找，然后再进行一遍，再一边。。。伪代码如下1234567while(lo&lt;hi)&#123; rank mi =(lo+hi)&gt;&gt;1; if(e&lt;A[mi]) bi=mi; else if(A[mi]&lt;e) lo=mi+1; else return mi;&#125; 算法复杂度的计算：T(n)=T(n-1)+O(1)=O(log n) 平均：O(1.5log n) ####2.fibonacci查找 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个就是二分查找的进化版，把fibonacci数组作为mi的取值。1 2 3 5 7这个数组。而且刚好都是黄金分割点。 ####3.插值查找&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设：已知有序向量中各元素随机分布的规律。 查字典就是一种插值查找的应用。 EX：如果e=50 lo=0 hi=18 mi=0+(18-0)*(50-5)(92-5)=9.3 mi=9 A[9]&lt;e lo=10 hi=18 mi=10+(18-10)*(50-49)/(92-49)=10.2 ####4.归并算法12345if(hi-io&lt;2) return;int mi=(lo+mi)&gt;&gt;1;mergeSort(lo,mi);mergeSort(mi,hi);merge(lo,mi,hi); ####5.堆栈&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中缀表达式 a+b*c-d/e 后缀表达式 abc*+de/-转化的方法： 1.运算符，直接输出。 2.左括号，压入堆栈 3.右括号，将栈顶的运算符弹出并输出，直到遇到左括号。 4.运算符，若优先级大于栈顶运算符，压栈。若优先级小于等于栈顶运算符，将栈顶运算符弹出并输出，再比较新的栈顶运算符，直到运算符大于栈顶运算符优先级为止，然后运算符压栈。 5.若各对象处理完毕，则把堆栈中存留的运算符一并输出。 ####6.队列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只能在一端输入，另外一端删除，头元素位置front 队尾元素位置 rear 循环队列的话front也只能在头rear在尾。 ####7.二叉树的一些&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有一个儿子的=有两个儿子的-1 二叉树遍历的本质：把二维结构线性化。 层序遍历的基本过程： 1.从队列中取出一个元素。 2.访问该元素所指的节点。 3.若该元素所指的节点的左右孩子节点非空，则将其左右孩子的指针顺序入队。 先序遍历和中序遍历可以推出整棵树。 ####PS原本以为记得挺多的，没想到就那么一些，期末了，开始刷一些数据结构的题目，下次把做错的题目发出来把~进度是这样的，学校已经把数据结构上完了， 浙大的看到了树（上）。 新年求女友~！","categories":[{"name":"-数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/categories/数据结构/"}],"tags":[{"name":"数据结构 求女友","slug":"数据结构-求女友","permalink":"https://wangkai1994.github.io/tags/数据结构-求女友/"}]},{"title":"leetcode爬坑（番外）","slug":"jiefangc","date":"2015-01-04T09:38:29.000Z","updated":"2015-01-04T09:55:13.000Z","comments":true,"path":"2015/01/04/jiefangc/","link":"","permalink":"https://wangkai1994.github.io/2015/01/04/jiefangc/","excerpt":"","text":"###番外：二分法求多项式单根(20) 二分法求函数根的原理为：如果连续函数f(x)在区间[a, b]的两个端点取值异号，即f(a)f(b)&lt;0，则它在这个区间内至少存在1个根r，即f(r)=0。二分法的步骤为：检查区间长度，如果小于给定阈值，则停止，输出区间中点(a+b)/2；否则如果f(a)f(b)&lt;0，则计算中点的值f((a+b)/2)；如果f((a+b)/2)正好为0，则(a+b)/2就是要求的根；否则如果f((a+b)/2)与f(a)同号，则说明根在区间[(a+b)/2, b]，令a=(a+b)/2，重复循环；如果f((a+b)/2)与f(b)同号，则说明根在区间[a, (a+b)/2]，令b=(a+b)/2，重复循环；本题目要求编写程序，计算给定3阶多项式f(x)=a3x3+a2x2+a1x+a0在给定区间[a, b]内的根。输入格式：输入在第1行中顺序给出多项式的4个系数a3、a2、a1、a0，在第2行中顺序给出区间端点a和b。题目保证多项式在给定区间内存在唯一单根。输出格式：在一行中输出该多项式在该区间内的根，精确到小数点后2位。输入样例：3 -1 -3 1-0.5 0.5输出样例：0.33 ####【一开始的思路】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这题的思路在题目中已经给出，直接按照提示写代码就好了。 12345678910111213141516171819202122232425262728293031323334353637#include&lt;stdio.h&gt;double a3=0,a2=0,a1=0,a0=0;double f(double x)&#123; return (a3*x*x*x+a2*x*x+a1*x+a0);&#125;double qiujie(double a,double b)&#123; double temp=0; if((f(a)*f(b))&lt;0)&#123; while(b-a&gt;0.00001)&#123; temp=f((a+b)/2); if(temp==0)&#123; break; &#125; else if (temp*f(a)&gt;0)&#123; a=(a+b)/2; &#125; else if(temp*f(b)&gt;0)&#123; b=(a+b)/2; &#125; &#125; &#125; else if(f(a)==0||f(b)==0)&#123; if(f(a)==0)&#123; return a; &#125; else if(f(b)==0)&#123; return b; &#125; &#125; return (a+b)/2;&#125;int main()&#123; double a,b; scanf(\"%lf %lf %lf %lf\",&amp;a3,&amp;a2,&amp;a1,&amp;a0); scanf(\"%lf %lf\",&amp;a,&amp;b); printf(\"%0.2lf\",qiujie(a, b));&#125; ####【算法的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一开始没有考虑到边界条件，所以一直错误。还是太年轻了。","categories":[{"name":"-算法","slug":"算法","permalink":"https://wangkai1994.github.io/categories/算法/"}],"tags":[{"name":"PAT","slug":"PAT","permalink":"https://wangkai1994.github.io/tags/PAT/"}]},{"title":"leetcode爬坑(4)","slug":"ReverseInteger","date":"2014-12-10T11:20:09.000Z","updated":"2014-12-10T11:33:00.000Z","comments":true,"path":"2014/12/10/ReverseInteger/","link":"","permalink":"https://wangkai1994.github.io/2014/12/10/ReverseInteger/","excerpt":"###4.Reverse Integer Reverse digits of an integer.Example1: x = 123, return 321Example2: x = -123, return -321","text":"###4.Reverse Integer Reverse digits of an integer.Example1: x = 123, return 321Example2: x = -123, return -321 ####【一开始的思路】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一题简单的逆序打印数字的题目，但是，可能今天是被冷风冻坏了脑子，脑洞打开想了好久甚至想到了数组，其实很简单，用% 和一个循环就可以搞定。1234567891011121314public class Solution &#123; public int reverse(int x) &#123; long temp=x,result=0; while(temp!=0)&#123; result=result*10; result=result+temp%10; temp=temp/10; &#125; if(Math.abs(result) &gt; 2147483647)&#123; return 0; &#125; return (int)result; &#125; &#125; ####【看了官方的解法】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NULL ####【关于java的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NULL ####【算法的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要考虑到int的最大值2147483647，也就是2的32次阶乘-1。超出了就返回0。 ####PS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近恶补数据结果，有很多收获，慢慢发。：）","categories":[{"name":"-算法","slug":"算法","permalink":"https://wangkai1994.github.io/categories/算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/tags/数据结构/"}]},{"title":"leetcode爬坑（2）& 数据结构绪论结尾","slug":"MinStack","date":"2014-11-24T14:13:31.000Z","updated":"2014-11-24T14:43:11.000Z","comments":true,"path":"2014/11/24/MinStack/","link":"","permalink":"https://wangkai1994.github.io/2014/11/24/MinStack/","excerpt":"###2.MinStack Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.push(x) – Push element x onto stack.pop() – Removes the element on top of the stack.top() – Get the top element.getMin() – Retrieve the minimum element in the stack.","text":"###2.MinStack Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.push(x) – Push element x onto stack.pop() – Removes the element on top of the stack.top() – Get the top element.getMin() – Retrieve the minimum element in the stack. ####【一开始的思路】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一题很贴切书本的题目，因为刚刚学完栈结构，我便马上翻开了书本，不过。。结构体在JAVA里怎么定义？不定义JAVA怎么初始化栈？好吧！我打开了dash搜索了stack关键字，好家伙，pop/peek/push/sreach居然都有，都包含在了stack的包中，还要啥自行车！直接一步到位了。但是最后一个关键问题：输出最小值怎么办？答案早已在胸中：再搞一个stack，如果push的比栈顶的小，就继续压入新的stack中。 那就整代码。不急，先百度下具体的使用例子，百度完以后，就明白了很多。我的代码如下：123456789101112131415161718192021222324252627282930package leedcode;import java.util.Stack;public class Minstack &#123; private Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); private Stack&lt;Integer&gt; min =new Stack&lt;Integer&gt;(); //初始化 public void push(int x) &#123; if(min.isEmpty()||x&lt;=min.peek())&#123; min.push(x); &#125; stack.push(x); &#125; public void pop() &#123; if (stack.peek().equals(min.peek())) &#123; min.pop(); &#125; stack.pop(); &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return min.peek(); &#125;&#125; ####【看了官方的解法】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和我几乎差不多，开心。 ####【关于java的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;知道了java中栈的实现，和C语言比方便了许多。 ####【算法的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要取栈的最小值，可以另建一个栈，一次存入比这个栈栈顶小的数。 ###数据结构绪论补充&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;迭代和递归：分而治之和减而治之。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;递推方程：T(n) = T(n-1)+O(1)化简等于 O(n)","categories":[{"name":"-算法","slug":"算法","permalink":"https://wangkai1994.github.io/categories/算法/"}],"tags":[{"name":"leetcode 数据结构","slug":"leetcode-数据结构","permalink":"https://wangkai1994.github.io/tags/leetcode-数据结构/"}]},{"title":"leetcode爬坑之路（1）","slug":"ReverseWordsinaString","date":"2014-11-23T09:34:46.000Z","updated":"2014-11-26T13:57:26.000Z","comments":true,"path":"2014/11/23/ReverseWordsinaString/","link":"","permalink":"https://wangkai1994.github.io/2014/11/23/ReverseWordsinaString/","excerpt":"&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近又发现一个大坑 leedcode ，很多毕业生毕业之前都会把里面的题目刷一遍，以解决招聘时遇到的算法问题。正好，最近我们在学java和数据结构，观察leedcode中基本上都会有用到数据结构和算法，正好又可以用java实现，顺便了解一下java类的使用。那么多东西可以一起实践，真是太棒了。所以果断着手开始做，我的方法一般是，先自己理解题目的意思，在草稿纸上写出自己的解决方法，再从别人的博客上看C++的实现方法，看不懂就先把题目AC了，再看官方的实现答案，去理解，最后自己独立完成一边。所以，不是以AC题目为主，而是学习为主。 PS:数据结构的绪论还没看完怎么办！！！周一必须看完更新！ Here we go~!","text":"&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近又发现一个大坑 leedcode ，很多毕业生毕业之前都会把里面的题目刷一遍，以解决招聘时遇到的算法问题。正好，最近我们在学java和数据结构，观察leedcode中基本上都会有用到数据结构和算法，正好又可以用java实现，顺便了解一下java类的使用。那么多东西可以一起实践，真是太棒了。所以果断着手开始做，我的方法一般是，先自己理解题目的意思，在草稿纸上写出自己的解决方法，再从别人的博客上看C++的实现方法，看不懂就先把题目AC了，再看官方的实现答案，去理解，最后自己独立完成一边。所以，不是以AC题目为主，而是学习为主。 PS:数据结构的绪论还没看完怎么办！！！周一必须看完更新！ Here we go~! ###1.Reverse Words in a String Given an input string, reverse the string word by word.For example,Given s = “the sky is blue”,return “blue is sky the”. ####【一开始的思路】 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;题目的意思很简单，就是把单词的顺序逆向输出。拿到题目我很快想起我似乎在C语言的练习题中遇到过，但是遗忘的很快，一下子居然无从下手，后来慢慢有了些许思路，用字符串数组的特效，检测到空格就记录。记录空格位置以后就把空格前的单词输出到另外一个字符串数组。 看了C++的实现方法以后：可以利用栈实现，可是java如何实现栈?不会，C++的实现方法看不懂，但是大致的思路已经清楚，和我想象的有些出入但是大致相似。 ####【看了官方的解法】 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;官方的解法非常漂亮，17行代码就搞定，后面的注释就是我的理解。 123456789101112131415161718192021package leedcode;public class ReverseWordsinaString &#123; public String reverseWords(String s) &#123; StringBuilder reversed = new StringBuilder();//创建srtingbuilder对象，可以理解成创建一个字符串？ int j = s.length(); for (int i = s.length() - 1; i &gt;= 0; i--) &#123; //逆向 if (s.charAt(i) == ' ') &#123; j = i; //利用变量j来定位空格的位置 &#125; else if (i == 0 || s.charAt(i - 1) == ' ') &#123;//前方空格预警！或者是前方到头了预警 if (reversed.length() != 0) &#123;//判断是不是输入的是不是只有一个空格 reversed.append(' '); &#125; //如果遇到了空格就向字符串中添加一个空格 reversed.append(s.substring(i, j));//此时j还没有被改变，所以赶紧把字符串i-j的位置的单词输出 &#125; &#125; return reversed.toString();//返回字符串 &#125;&#125; ####【关于java的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;知道了stringbuilder的使用情况，里面的append()方法是向这个字符串添加内容的。substring(i, j)方法的用法，可以截取字符串中的一段。 ####【算法的收获】&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过循环变量的逆序来实现逆序输出（实际上早就用过可是想不起来）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;嗯，第一个题目就结束了，希望不是最后一个！","categories":[{"name":"-算法","slug":"算法","permalink":"https://wangkai1994.github.io/categories/算法/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://wangkai1994.github.io/tags/leetcode/"}]},{"title":"数据结构笔记1","slug":"sjjg1","date":"2014-11-17T16:16:00.000Z","updated":"2014-11-17T17:08:09.000Z","comments":true,"path":"2014/11/18/sjjg1/","link":"","permalink":"https://wangkai1994.github.io/2014/11/18/sjjg1/","excerpt":"在学校里的数据结构课程上的很不令我满意，一是老师的讲课不够生动，二是教材很凌乱。在网上寻觅很久，发现了两处不错的网络课程，权当课堂的补充。","text":"在学校里的数据结构课程上的很不令我满意，一是老师的讲课不够生动，二是教材很凌乱。在网上寻觅很久，发现了两处不错的网络课程，权当课堂的补充。 第一个是网易云课堂，12月1日开课，我会在开课后跟进。 第二个是我现在所学的学堂在线,课程已经过半。 下面是我的课堂笔记。 ##第一章：绪论 ###1.级数 从衡量算法好坏的尺度入手，利用 大O 符号 θ 符号 Ω符号，以此是上限和下限的意思，但是我们还是更加关注与大O符号。 算数数级-&gt;末项平方同阶 EX：1+2+3+…+n=O(n^2) 幂-&gt;幂次+1 EX：1^2+2^2+3^2+……+n^2=O(n^3) 几何数级-&gt;与末项同阶 EX：a^0+a^1+a^2+……+a^n=O(a^n) 收敛-&gt;O(1) 1+1/2+1/3+…+1/n = θ(log n) 调和级数 log1+log2+log3+…+logn = log(n!) = θ(n logn) 对数级数 ###2.循环 12for(i=n ;i&lt; n;i++) for(j= l;j&lt;l ;j++) 控制变量若无耦合，则是算术数级O(n^2) i&lt;&lt;=1 等效与 i=i*2 若有耦合，即j与i有联系，则为几何数级 ###3.正确性 不变性：经过K次后，最大的K必须就位 单调性：经过K次后，问题规模为n-k次 经过K此后必须停止则为正确 上周就那么多，1节课的内容，下周继续！keep moving!","categories":[{"name":"-数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wangkai1994.github.io/tags/数据结构/"}]},{"title":"无题","slug":"no-title","date":"2014-11-08T17:07:00.000Z","updated":"2014-11-08T17:12:28.000Z","comments":true,"path":"2014/11/09/no-title/","link":"","permalink":"https://wangkai1994.github.io/2014/11/09/no-title/","excerpt":"","text":"还在想在火车站门口那双渴望交汇的眼神，踱着恍惚的步子，手中端着早已知道的结局。 凌晨的睡意与你的咖啡因，满屏幕的爱与不爱。 那段总是闲太短的又闲太长的上坡或者下坡，那杯忽冷忽热能是奥利奥有可能是巧克力的奶茶。 以为至少我能做的是把我们的影子重叠在一起，却发现你总是在看灯。 约会就是一场蓄谋已久的自杀，借口似乎都不需要。 火拼已久终于溢出口中的几个字和由脑细胞控制的肢体终于开始行动，确认拥有一颗会跳的心。 手冷，慌乱了眼神，恶心的“对不起”是心中裂出了旧伤的脓液。 迫切的让世界知道我的存在，不惧起承转合。 太短的路和已经通道彼此脑中的路连在了一起，铺出一条彩虹或者通向地狱。 摇曳的树被路灯投影下了数的清的叶子，门口的那句很愉快在心中是不是一个分子式。 才想起手里捏着早已经捏烂的水瓶，塞进了我所有的遗憾以后扔进了它的归宿。 你的转身好像不仅仅是一片裙摆，而是那种吹了让树发芽的风。 而我的，是冬天。 深夜、你是咖啡 我是安定片。 你的习惯我的错觉剂。 最后没有告别的告别，似乎根本没有这一些的起承转合。 臆想的功力总是大于我的为你而生的胆量。 你已经写在了我的时间线上，哪怕有用的只是回忆。 或者，还有这半夜，操这心中的思绪，写着忽高忽低的随笔。 愿你也安好。","categories":[{"name":"-随笔","slug":"随笔","permalink":"https://wangkai1994.github.io/categories/随笔/"}],"tags":[]},{"title":"smartisan(锤子)手机降价引发的一系列思考","slug":"20141103","date":"2014-11-02T17:07:00.000Z","updated":"2014-11-08T17:15:36.000Z","comments":true,"path":"2014/11/03/20141103/","link":"","permalink":"https://wangkai1994.github.io/2014/11/03/20141103/","excerpt":"","text":"##行业系列导语&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个系列是记录的是我个人对于这个行业（互联网IT）的一些思考，这种思考写在这里便成了文章，在此先说明，文章只供娱乐和练文笔。以后的文章不会像以前一样瞎写想到哪里写哪里，会更加有条理些。 ###1.引言&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在前几天的一个早晨，正好在上水课的我掏出手机逛CHH突然看见新闻板块有一条新闻说锤子手机降价了，我并不以外，距离上一次听见锤子的新闻已经过去了几周还是几个礼拜。印象中暑假“王自如和罗永浩撕逼大战”以后，锤子的热度就下去了。平时生活中，有几个瞬间会想起锤子是不是要倒闭了，但是还是不会太注意，直到降价的消息传出。慌忙之中去翻看了罗永浩的微博，只看见这样一条： 最近我也最近我经常在反省这件事：让我们的用户遭受了这么多的冷嘲热讽，基本上都是因为我的言谈作风。作为一个人，我问心无愧；作为一个企业家，我太不职业。 仔细思考这个降价1000的消息，在和罗永浩最近的言论结合在一起，查了一下T1的销售情况，出货量，发现这一决定其实并不意外。终于是纸包不住火。 ###2.smartisan的错&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记得在看第一财经的时候就知道，一家公司，无论是创业的小公司还是世界500强，都脱不开这样一个商业概念： idea-&gt;R&amp;D-&gt;Model-&gt;Design-&gt;Product-&gt;Marketing-&gt;Sales-&gt;Aftersales 可以给大家贴张图： 可能有些区别但是大体上是相同的，研发（设计），供应链，生产，市场营销，销售，以及售后是一个严丝合缝的整体。锤子科技就只单单在设计和市场营销方面发力，其他板块可以说都是不及格或者刚刚及格，所以这样下去它的下场是显而易见的。作为一家小型创业的企业，模仿的模式却是苹果—坚持以设计为导向来定义产品。但是明显的就是忽略了自己的体量和自己在这个行业的经验。苹果什么厉害，就是把设计转化为产品的过程厉害，他们的文化就是有棒的idea就坚持做到完美。在cook之前，产量问题也是它的诟病，被迫被称为饥饿营销。但是Cook上手后，理顺了供应链的关系，可谓进退自如，领先别家几年的技术，同时实验新技术，失败也有足够的资源作为缓冲。可以很负责的说，经过了那么多年，苹果在研发（设计），供应链，生产，市场营销，销售，以及售后都是行业的翘楚。真正做好了这些才能真正把一个自己完美的设计展现在人们手里。 作为掌门人的罗永浩当然知道这些基本道理，但是他没有对供应链的操控，他把这个行业想的太简单。这也是我为什么一直佩服小米的原因，虽然产品不出众，一直在模仿借鉴，但是不得不说在产业链上，雷军已经有了一定话语权，并且在其他方面也在有条不紊的前进，不得不说目前来说小米是最接近苹果的中国公司，思路够清楚！ 种种的原因也就导致了在T1的销售黄金前4月，出现了没货可卖的窘境，难以为继，被迫降价1000元。 ###3.罗永浩的自我营销&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看以下两个例子1.罗永浩一直试图想要让观众相信，考虑到这是一家小企业，这部手机应该打200分，能够与之相比的只有iPhone。2.罗永浩在自身宣传当中，自称：“我感觉再次被时代选中了”，而锤子科技在手机宣传当中，也继承了这一风格，称T1 为“东半球最好用的手机”。;不得不说，罗永浩的口才和他的营销能力是相符的。但是在宣传的时候，太已自己的理想为基准，完全忽略了自己团队的能力和执行力。 他自己本身几乎垄断了smartisan的对外宣传工作，听说去年在MiuiV5发布时，与小米的论战，让罗永浩发出命令，禁止团队当中其他人代表锤子科技进行发声。这也不得不让我们这些关注自然的把锤子科技的形象和罗永浩结合了起来。然而，对比现实和微博，忽略自己的执行力，经验的欠缺，让T1在质量和销量都处在岌岌可危的边缘。本来在发布会结束后，就出现了一批相信情怀与诚信的那一批死忠用户，也因为与现实反差太大的营销，产生了一定的动摇，毕竟3150的价格快可以买两部1799了，虽然同样是买不到。然后又是在天猫的情怀乘3事件，舆论铺满了锤子科技，这本身就是罗永浩长期垄断营销渠道，过度营销，透支信誉的苦果。当这些用户从热情的支持转到冷静的旁观时，尝试新品的前5%的用户，无法吸引并且拉动更多的人时，Smartisan 的推广路径也就彻底的封闭了。 ###4.结语&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;没有企业不会犯错，就像大学生都会犯错一样，犯错了不任性，改回来可能还有补救的余地。降价的行为本身，就是锤子科技为前面罗永浩犯下的错买单。降1000作为最后的杀手锏，也表明了锤子科技的决心，请注意，我没把罗永浩和锤子手机混在一起。 我觉得值得我学习的是，罗永浩在失败过后痛改前非，果断转型。连发了数条痛改前非的微博，不再扭曲事实。在这一次失败之后，相信锤子科技也会吸取其中供应链与产能的教训，更好的协调设计与生产之间的关系。 比起5月20日，锤子科技通向苹果的大门，已经关上了不少，不知道今天锤子手机这一降价与转型，能否扼住命运的咽喉。 ###5.PS：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这篇文章，是本人第一次用markdown语法写，不免在有些地方贻笑大方，希望谅解。本文思路也是参考了知乎上的高票回答，大神给了我很多商业上的想法。另外，这次调试hexo也给我带来很大的收获，有空可以补上教程和修改bug的过程，下次更新希望是一周，我会写学习java过程中的收获，编程为主！THANKS&lt;","categories":[{"name":"-行业","slug":"行业","permalink":"https://wangkai1994.github.io/categories/行业/"}],"tags":[]}]}